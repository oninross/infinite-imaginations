{"caseStudies":[{"title":"Elements","category":"coding","tldr":"An offline Progressive Web Application (PWA) of the periodic table of elements displaying the different information of the element.","role":"Front-end Developer / Interface Designer","challenges":["Mobile apps are restricted to their respective app stores.  Creating tools will be more useful to everyone if there were no barriers.  I needed to deliver the content to the users quick and easy."],"solutions":["Elements is a progressive web app with a responsive mobile site in its core. Users can visit the page in their mobile devices, tablets and or desktops to view the periodic table of elements.  Users in Chrome Android will be prompted with a notification if they want to ‚Äúpin‚Äù the page in their home screens. The icon in turn looks like an app, opens up like an app, and behaves like an app. The best part is that even if there is no internet connection, users can still view use the app."],"technology":["HTML / HTML5","CSS / CSS3","JavaScript / jQuery / TweenMax"],"images":{"large":{"url":"/infinite-imaginations/assets/infiniteimaginations/images/large-elements.png","padding":61},"small":"/infinite-imaginations/assets/infiniteimaginations/images/small-elements.jpg"},"url":{"live":"http://elements.infiniteimaginations.co","local":"/infinite-imaginations/#/case-study/elements"}},{"title":"Physical Web and Beacons","category":"coding","tldr":"Hassle free delivering of on demand information to the user by using the beacons and the Physical Web.","role":"Front-end Developer / UX Consultant","challenges":["Information can be at times be troublesome to the users.  Most of it is through the use of apps.  Apps are restricted by their own manufacturers and most of the time the app the users need are not supported by their devices."],"solutions":["Through the use of beacons, information can be delivered to the users easily.  There wouldn‚Äôt be a need of searching through millions of apps in the app store and downloading anymore.  Beacons transmit Eddystone URLs regularly to nearby mobile devices where the user can just tap the notification bringing them to a page with the relevant information.  It could be a web app telling the users the bus schedule of a particular bus stop or it could be a simple wayfinder in a museum or shopping mall.  The limitations are endless."],"technology":["HTML / HTML5","CSS / CSS3","JavaScript / jQuery / TweenMax"],"images":{"large":{"url":"/infinite-imaginations/assets/infiniteimaginations/images/large-physical-web.png","padding":60},"small":"/infinite-imaginations/assets/infiniteimaginations/images/small-physical-web.jpg"},"url":{"live":null,"local":"/infinite-imaginations/#/case-study/physical-web"}},{"title":"Adelphi Digital","category":"coding","tldr":"Adelphi Digital needed a new responsive website to cater its new content.  We also needed to make a clear statement to the world, <strong><em>\"we are going to create a complete agency website in 4 days.\"</em></strong>","role":"Front-end Developer","challenges":["Everything was being done in one stream simultaneously.  We had one approved template design, the other templates were either still being designed or being revised, and I was the only front-ender to convert everything to HTML."],"solutions":["I had to make sure that the core framework of the website was robust yet flexible to fit any kind of content based from the design, and easy enough for the team to take over and populate the content.  It was just pure hard-work, passion and motivation that pushed us all to finish the website."],"technology":["HTML / HTML5","CSS / CSS3","JavaScript / jQuery / TweenMax"],"images":{"large":{"url":"/infinite-imaginations/assets/infiniteimaginations/images/large-adelphi-digital.png","padding":61},"small":"/infinite-imaginations/assets/infiniteimaginations/images/small-adelphi-digital.jpg"},"url":{"live":"http://adelphi.digital","local":"/infinite-imaginations/#/case-study/adelphi-digital"}},{"title":"infinite imaginations BETA","category":"design","tldr":"A revolutionary and cutting edge website in design and technology, where most developers barely knew about the existing resources in the internet and the possibilities that it can do.","role":"Front-end Developer / Designer","challenges":["The main objective was to animate the website using plain HTML.  The site was previously done in Flash and I needed to convert it to HTML.  Oh yeah, I was a noob in coding HTML."],"solutions":["With a crash course in HTML, CSS and JavaScript, I managed to replicate what I have done in Flash by using TweenMax and CSS3.  GreenSock just came out with its JavaScript version of their Flash plugin and I had just to be the first one to implement it. The website was featured in Web Designers Magazine."],"technology":["HTML / HTML5","CSS / CSS3","JavaScript / jQuery / TweenMax"],"images":{"large":{"url":"/infinite-imaginations/assets/infiniteimaginations/images/large-infinite-imaginations-beta.png","padding":61},"small":"/infinite-imaginations/assets/infiniteimaginations/images/small-infinite-imaginations-beta.jpg"},"url":{"live":"http://beta.infiniteimaginations.co","local":"/infinite-imaginations/#/case-study/infinite-imaginations-beta"}},{"title":"The Jewel Box","category":"design","tldr":"An interactive touch screen to showcase the different venues and history about Mt. Fabre in different languages.","role":"Interface Designer / Flash Developer","challenges":["We were provided with a low-powered machine to drive the touch screen, and we needed to display a lot of information in the device.  We also had to make sure that the interface was user-friendly for users who didn‚Äôt know how to use a touch screen."],"solutions":["We managed to deliver large amounts of content in different languages using XML.  Flash was still alive and mainstream and Apple was our peg.  By following the principles of Apple, we managed to make the user interface easy to use for anyone."],"technology":["Flash ActionScript 3","TweenMax for ActionScript","XML"],"images":{"large":{"url":"/infinite-imaginations/assets/infiniteimaginations/images/large-the-jewel-box.png","padding":70},"small":"/infinite-imaginations/assets/infiniteimaginations/images/small-the-jewel-box.jpg"},"url":{"live":null,"local":"/infinite-imaginations/#/case-study/the-jewel-box"}},{"title":"Envirobot","category":"design","tldr":"An interactive touchscreen application built into the chassis of a remote controlled robot circulating around Singapore high schools for students to play around with and at the same time learn about the environment.","role":"Interface Designer / Flash Developer","challenges":["The iPad was already out in the market and users will expect a smooth user experience.  Touch screens on a Windows machine was just a simple tap here and a tap there.  We needed to make the application interesting enough for students to engage with it."],"solutions":["We took Apple as our basis for all the interaction and design guidelines.  We made sure that the design will be appealing to the student and yet intuitive enough for them to know how to use it.  Most of the time, I just had fun animating and creating the application.  It was probably one of the most funnest projects that I have worked on because we had the freedom to pour our creative juices into the project."],"technology":["Flash ActionScript 3","TweenMax for ActionScript"],"images":{"large":{"url":"/infinite-imaginations/assets/infiniteimaginations/images/large-envirobot.png","padding":70},"small":"/infinite-imaginations/assets/infiniteimaginations/images/small-envirobot.jpg"},"url":{"live":null,"local":"/infinite-imaginations/#/case-study/envirobot"}}],"articles":[{"title":"Using Artificial Intelligence to Generate Alt Text on Images","url":"/infinite-imaginations/#/article/using-artificial-intelligence-to-generate-alt-text-on-images","content":"<p>Web developers and content editors alike often forget or ignore one of the most important parts of making a website accessible and SEO performant: image alt text. You know, that seemingly small image attribute that describes an image:</p><code>&lt;img src='/cute/sloth/image.jpg' alt='A brown baby sloth staring straight into the camera with a tongue sticking out.' &gt;</code><img src='/infinite-imaginations/assets/infiniteimaginations/images/articles/sloth.jpeg' alt='A brown baby sloth staring straight into the camera with a tongue sticking out.'><p class='-caption'>üì∑ Credit: <a href='https://www.huffingtonpost.com/2014/04/17/baby-sloth-compilation_n_5160060.html' target='_blank'>Huffington Post</a></p><p>If you regularly publish content on the web, then you know it can be tedious trying to come up with descriptive text. Sure, 5-10 images is doable. But what if we are talking about hundreds or thousands of images? Do you have the resources for that?</p><p>Let‚Äôs look at some possibilities for automatically generating alt text for images with the use of computer vision and image recognition services from the likes Google, IBM, and Microsoft. They have the resources!</p><h2>Reminder: What is alt text good for?</h2><p>Often overlooked during web development and content entry, the alt attribute is a small bit of HTML code that describes an image that appears on a page. It‚Äôs so inconspicuous that it may not appear to have any impact on the average user, but it has very important uses indeed:</p><ul><li><strong>Web Accessibility for Screen Readers:</strong> Imagine a page with lots of images and not a single one contains <code>alt</code> text. A user surfing in using a screen reader would only hear the word ‚Äúimage‚Äù blurted out and that‚Äôs not very helpful. Great, there‚Äôs an image, but what is it? Including <code>alt</code> enables screen readers to help the visually impaired ‚Äúsee‚Äù what‚Äôs there and have a better understanding of the content of the page. They say a picture is worth a thousand words ‚Äî that‚Äôs a thousand words of context a user could be missing.</li><li><strong>Display text if an image does not load:</strong> The World Wide Web seems infallible and, like New York City, that it never sleeps, but flaky and faulty connections are a real thing and, if that happens, well, images tend not to load properly and ‚Äúbreak.‚Äù Alt text is a safeguard in that it displays on the page in place of where the ‚Äúbroken‚Äù image is, providing users with content as a fallback.</li><li><strong>SEO performance:</strong> Alt text on images contributes to SEO performance as well. Though it doesn‚Äôt exactly help a site or page skyrocket to the top of the search results, it is one factor to keep in mind for SEO performance.</li></ul><p>Knowing how important these things are, hopefully you‚Äôll be able to include proper <code>alt</code> text during development and content entry. But are your archives in good shape? Trying to come up with a detailed description for a large backlog of images can be a daunting task, especially if you‚Äôre working on tight deadlines or have to squeeze it in between other projects.</p><p>What if there was a way to apply alt text as an image is uploaded? And! What if there was a way to check the page for missing alt tags and automagically fill them in for us?</p><h2>There are available solutions!</h2><p>Computer vision (or image recognition) has actually been offered for quite some time now. Companies like Google, IBM and Microsoft have their own APIs publicly available so that developers can tap into those capabilities and use them to identify images as well as the content in them.</p><p>There are developers who have already utilized these services and created their own plugins to generate alt text. Take <a href='https://codepen.io/sdras/details/jawPGa' target='_blank'>Sarah Drasner‚Äôs generator</a>, for example, which demonstrates how Azure‚Äôs Computer Vision API can be used to create alt text for any image via upload or URL. Pretty awesome!</p> <p class='codepen' data-height='600' data-theme-id='1' data-default-tab='result' data-user='sdras' data-slug-hash='jawPGa' style='height: 604px; box-sizing: border-box; display: flex; align-items: center; justify-content: center; border: 2px solid black; margin: 1em 0; padding: 1em;' data-pen-title='Dynamically Generated Alt Text with Azure&amp;apos;s Computer Vision API'>‚Äã‚Äã<span>See the Pen <a href='https://codepen.io/sdras/pen/jawPGa/'>‚Äã‚ÄãDynamically Generated Alt Text with Azure&apos;s Computer Vision API</a> by Sarah Drasner (<a href='https://codepen.io/sdras'>@sdras</a>)‚Äã‚Äãon <a href='https://codepen.io'>CodePen</a>.</span>‚Äã‚Äã</p><script async src='https://static.codepen.io/assets/embed/ei.js'></script><p>There‚Äôs also <a href='https://wordpress.org/plugins/automatic-alternative-text/' target='_blank'>Automatic Alternative Text</a> by Jacob Peattie, which is a WordPress plugin that uses the same Computer Vision API. It‚Äôs basically an addition to the workflow that allows the user to upload an image and generated <code>alt</code> text automatically.</p><p>Tools like these generally help speed-up the process of content management, editing and maintenance. Even the effort of thinking of a descriptive text has been minimized and passed to the machine!</p><h2>Getting Your Hands Dirty With AI</h2><p>I have managed to have played around with a few AI services and am confident in saying that Microsoft Azure‚Äôs Computer Vision produces the best results. The services offered by Google and IBM certainly have their perks and can still identify images and proper results, but Microsoft‚Äôs is so good and so accurate that it‚Äôs not worth settling for something else, at least in my opinion.</p><p>Creating your own image recognition plugin is pretty straightforward. First, head down to <a href='https://azure.microsoft.com/en-au/services/cognitive-services/computer-vision/' target='_blank'>Microsoft Azure Computer Vision</a>. You‚Äôll need to login or create an account in order to grab an API key for the plugin.</p><p>Once you‚Äôre on the dashboard, search and select Computer Vision and fill in the necessary details.</p> <img src='/infinite-imaginations/assets/infiniteimaginations/images/articles/dashboard01.png' alt='Screenshot of Microsoft Azure dashboard'><p>Wait for the platform to finish spinning up an instance of your computer vision. The API keys for development will be available once it‚Äôs done.</p> <img src='/infinite-imaginations/assets/infiniteimaginations/images/articles/dashboard02.png' alt='Screenshot of API keys'><p>Let the interesting and tricky parts begin! I will be using vanilla JavaScript for the sake of demonstration. For other languages, you can check out the <a href='https://westus.dev.cognitive.microsoft.com/docs/services/56f91f2d778daf23d8ec6739/operations/56f91f2e778daf14a499e1fe' target='_blank'>documentation</a>. Below is a straight-up copy and paste of the code and you can use to replace the placeholders.</p><pre> <code>var request = new XMLHttpRequest();<br/> request.open('POST', 'https://[LOCATION]/vision/v1.0/describe?maxCandidates=1&language=en', true);<br/> request.setRequestHeader('Content-Type', 'application/json');<br/> request.setRequestHeader('Ocp-Apim-Subscription-Key', '[SUBSCRIPTION_KEY]');<br/> request.send(JSON.stringify({ 'url': '[IMAGE_URL]' }));<br/> request.onload = function () {<br/> &nbsp;&nbsp;&nbsp;&nbsp;var resp = request.responseText;<br/> &nbsp;&nbsp;&nbsp;&nbsp;if (request.status >= 200 && request.status < 400) {<br/> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;// Success!<br/> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;console.log('Success!');<br/> &nbsp;&nbsp;&nbsp;&nbsp;} else {<br/> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;// We reached our target server, but it returned an error<br/> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;console.error('Error!');<br/> &nbsp;&nbsp;&nbsp;&nbsp;}<br/> &nbsp;&nbsp;&nbsp;&nbsp;console.log(JSON.parse(resp));<br/> };<br/><br/> request.onerror = function (e) {<br/> &nbsp;&nbsp;&nbsp;&nbsp;console.log(e);<br/> };</code> </pre><p>Alright, let‚Äôs run through some key terminology of the AI service.</p><ul><li> <strong>Location:</strong> This is the subscription location of the service that was selected prior to getting the subscription keys. If you can‚Äôt remember the location for some reason, you can go to the Overview screen and find it under Endpoint. <img src='/infinite-imaginations/assets/infiniteimaginations/images/articles/dashboard03.png' alt='Screenshot of Endpoint'></li><li><strong>Subscription Key:</strong> This is the key that unlocks the service for our plugin use and can be obtained under Keys. There‚Äôs two of them, but it doesn‚Äôt really matter which one is used.</li><li> <strong>Image URL:</strong> This is the path for the image that‚Äôs getting the alt text. Take note that the images that are sent to the API must meet specific requirements:<ul><li>Accepted formats: JPEG, PNG, GIF, BMP</li><li>File size must be less than 4MB</li><li>Dimensions should be greater than 50px by 50px</li></ul></li></ul><h2>Easy Peasy</h2><p>Thanks to big companies opening their services and API to developers, it‚Äôs now relatively easy for anyone to utilize computer vision. As a simple demonstration, I uploaded the image below to Microsoft Azure‚Äôs Computer Vision API.</p><img src='/infinite-imaginations/assets/infiniteimaginations/images/articles/cellphone.png' alt='a hand holding a cellphone'><p>The service returned the following details:</p><pre> <code> {<br/> &nbsp;&nbsp;&nbsp;&nbsp;'description': {<br/> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'tags': [<br/> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'person',<br/> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'holding',<br/> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'cellphone',<br/> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'phone',<br/> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'hand',<br/> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'screen',<br/> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'looking',<br/> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'camera',<br/> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'small',<br/> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'held',<br/> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'someone',<br/> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'man',<br/> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'using',<br/> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'orange',<br/> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'display',<br/> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'blue'<br/> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;],<br/> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'captions': [<br/> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{<br/> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 'text': 'a hand holding a cellphone',<br/> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 'confidence': 0.9583763512737793<br/> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}<br/> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;]<br/> &nbsp;&nbsp;&nbsp;&nbsp;},<br/> &nbsp;&nbsp;&nbsp;&nbsp;'requestId': '31084ce4-94fe-4776-bb31-448d9b83c730',<br/> &nbsp;&nbsp;&nbsp;&nbsp;'metadata': {<br/> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'width': 920,<br/> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'height': 613,<br/> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'format': 'Jpeg'<br/> &nbsp;&nbsp;&nbsp;&nbsp;}<br/> } </code> </pre><p>From there, you could pick out the <code>alt</code> text that could be potentially used for an image. How you build upon this capability is your business:</p><ul><li>You could create a CMS plugin and add it to the content workflow, where the <code>alt</code> text is generated when an image is uploaded and saved in the CMS.</li><li>You could write a JavaScript plugin that adds <code>alt</code> text on-the-fly, after an image has been loaded with notably missing <code>alt</code> text.</li><li>You could author a browser extension that adds <code>alt</code> text to images on any website when it finds images with it missing.</li><li>You could write code that scours your existing database or repo of content for any missing <code>alt</code> text and updates them or opens pull requests for suggested changes.</li></ul><p>Take note that these services are not 100% accurate. They do sometimes return a low confidence rating and a description that is not at all aligned with the subject matter. But, these platforms are constantly learning and improving. After all, Rome wasn‚Äôt built in a day.</p>"},{"title":"2018: The Year of Artificial Intelligence","url":"/infinite-imaginations/#/article/2018-the-year-of-artificial-intelligence","content":"<p>Another year has passed by quickly‚Ää‚Äî‚Ääthis year however, has been consistent. Artificial intelligence (AI) has been constantly making tech headlines and I have been fortunate enough to be able to play around with some of it. As technology grows and evolves at an exponential rate, what does AI have to offer for us in the future?</p><h2>Artificial Intelligence - AI will continue to improve, for better or worst</h2><p><img src='/infinite-imaginations/assets/infiniteimaginations/images/articles/1_2wOWJr-i7MU_D25_M1rvTA.gif' alt='Neural Network'></p><p>JARVIS, Skynet and Hal are a few of the well-known self-aware and sentient computer programs in science fiction. While these characters may not be far away from the distant future, companies like Google and IBM are continuously developing systems to either help us to do a particular task faster or just be better than us humans, hoping that one day robots or androids will be there for us to do the dirty work. AI has at one point has alarmed people of losing their jobs. Just relax because at this point in time, AI is only capable in excelling at very specific areas.</p><p>With the aid machine learning, we will see companies utilise AI to automate tasks such as fast and accurate data learning, autonomous mobile robots, digital assistants and conversational platforms to name just a few. We first saw AI been implemented in smartphones such as Apple‚Äôs Siri and Google‚Äôs Assistant and in the recent months, we have seen a sudden surge of smart speakers being released to the consumers. AI will continue to spread like wildfire across the industry in the years to come. In 2019, we will definitely see more of AI being integrated into other devices, helping us accomplish more tasks quickly without us humans getting our hands dirty.</p><h2>Conversational Platforms - ‚ÄúHello, how can I help you today?‚Äù</h2><p><img src='/infinite-imaginations/assets/infiniteimaginations/images/articles/1_1ufACyatUum6CY2Uf5Dl9A.gif' alt='Google Assistant animation'></p><p>‚ÄúOk Google, Hey Siri, Alexa,‚Äù the initialising commands of Google‚Äôs, Apple‚Äôs and Amazon‚Äôs personal assistants. The platforms developed by their respective tech companies have paved way and developed speech recognition algorithms with the use of artificial intelligence and machine learning. Chatbots hit the industry and initially posed as a threat for call centres helping to take the load off the people by answering most frequently asked questions or help consumers purchase items through a conversation without the need of a human behind the wheel.</p><p>During the peak of its hype cycle, I have experimented with the technology and <strong><em><a href='/infinite-imaginations/infinite-imaginations/#/article/what-i-have-learned-from-building-a-chatbot'>learned a few things about building a chatbot</a></em></strong>. One of the most important lessons that I have learned is that ‚Äúone should never build a chatbot just because of the hype‚Äù because this will be the failure of the project. In 2019, consumers are more likely accept these conversational platforms as tech companies continue to develop and improve these platforms. Because it is really easy to create a chatbot, we will see more of these chatbots popping out everywhere We might even be <strong><em><a href='http://nat-ai.herokuapp.com/'>conversing with one</a></em></strong> without knowing it.</p><h2>Being online, all the time - Smartphones usage will steadily increase</h2><p><img src='/infinite-imaginations/assets/infiniteimaginations/images/articles/1_zSNn0IYxeaTypaptJ6YRvg.gif' alt='Timelapse of people passing by'></p><p>We all know that our smartphone is our ‚Äúdigital Swiss army knife‚Äù and we could not leave home without it. Browsers has been the platform to get users to the internet and tech companies are continuously improving their products to meet the demands of their loyal consumers. Besides improving the battery life, screen size, and camera quality, Google and Apple have integrated AI into their software providing an improved and smoother user experience. Not only that you have a virtual assistant with you in your phone all the time, it also learns and ‚Äúpredicts‚Äù the apps that you might be mostly using next at that specific time of the day.</p><p>There is no stopping of browsers to improve in 2019 and the years to come. Browsers are gaining features and capabilities that are becoming more ‚Äúnative‚Äù and ‚Äúapp-like.‚Äù Machine learning has even landed on browsers and I have managed to play around with such technologies that enabled me to <strong><em><a href='/infinite-imaginations/infinite-imaginations/#/article/identifying-objects-using-your-browser-with-tensorflowjs'>detect objects using a camera and a web browser</a></em></strong>. Developers are even planning to get virtual and augmented reality as a standard to web browsers in able to get more users to have an immersive experience without the need to download an app.</p><h2>Super Duper Hyper-personalisation - Better customer experience means more loyal customers</h2><p><img src='/infinite-imaginations/assets/infiniteimaginations/images/articles/1_67lTiMnxu3Nmevy1kWLdow.gif' alt='Ross doing a weird dance'></p><p>I open up my browser and start browsing at Facebook or Amazon and at first I didn‚Äôt notice it, but I saw a familiar pattern: I see ads or posts that were related to my past searches. I listen to Spotify, watch videos on YouTube or movies on Netflix and I noticed the music or movies being presented were of my interest. I didn‚Äôt tell anyone nor did save any preferences. It just happened. What is this sorcery?</p><p>With the advent of personalisation, it wasn‚Äôt enough for people to just read their names in emails from sites and services that they have subscribed to. That was already standard in digital marketing. Hyper-personalisation took it a step further by customising the person‚Äôs customer experience or journey by providing the things that they want or more interested in. In the years to come, hyper-personalisation with the help of AI will enable companies to provide the things their consumers want or interested at as quick as possible, providing better customer experience and making them loyal to the brand. Better customer experience means more loyal customers. More loyal customers means more money to the company. And I‚Äôm a sucker at that.</p><h2>Autonomous Mobile Robots - Robots running and opening doors, sh*t is getting real</h2><p><img src='/infinite-imaginations/assets/infiniteimaginations/images/articles/1_Wu2jGy1K3vgnywqllpNxDw.gif' alt='Boston Dynamics Atlas Robot Does Parkour'></p><p>I always thought that drones would only be a rich-man‚Äôs toy, flying around in open spaces and take photos or videos that were impossible to be taken by anyone. With drones becoming more cheaper, they are now being utilised to transport packages, food or other goods to places. These unmanned aerial vehicles (UAV) can help deliver medical supplies to inaccessible places. Backed up with AI, these UAVs are not aided anymore by humans. They are programmed in such a way that they know what to do in case something goes wrong. They know where to go and how to come back to headquarters without human intervention.</p><p>After watching Black Mirror‚Äôs episode titled Metalhead and a short video of Boston Dynamics‚Äô robots, the future got a little bit exciting (or scarier depending on how you look at it). With drones now capable to deliver goods, a robot that can do parkour, and a dog that can open doors, it is certainly clear that the dream of having a robot or android as a helper will be coming to help us in the near future. Maybe one day, we might just have our own Threepio helping us.</p><h2>Bonus Round: Immersive Experience (AR, &amp; VR) - Merging digital world with physical world</h2><p><img src='/infinite-imaginations/assets/infiniteimaginations/images/articles/1_Txkr8mn8JXsPPFuia46djQ.gif' alt='Lego Brickheadz AR demo'></p><p>Augmented reality and virtual reality has been going on for some time now. However it only has gain most of its traction in the gaming sector. The most notable AR game is Pokemon Go, where players get to ‚Äúexercise‚Äù by walking around the physical world in search for Pokemons in the digital world. VR games too are attracting popularity by immersing players into another world. They can see, hear and interact in the virtual world that they are thrown into. Tech companies such as Zero Latency and VR Zone Shinjuku offer VR experiences to the public. I was lucky enough to have enjoyed and experienced VR games in Japan and I would say that it is not only fun, but a memorable experience for any gamers.</p><p>AR and VR has now expanded their reach beyond the world of gaming. In the next few years, it would reach training, education and tourism sectors just to name a few. Some already has embraced the technology and provided immersive experiences to their customers. Retail companies have invested in AR booths, where their customers can try on clothes without even removing their own in a virtual world. As tech companies like Google and Mozilla developing to make AR and VR to be a standard in browsers, I believe that one day, we will one day see more <strong>*<a href='/infinite-imaginations/infinite-imaginations/#/article/vr-and-ar-in-the-mobile-web'>immersive experiences in the mobile web*</a></strong>.</p><h2>Wrapping it up: The future is bright</h2><p><img src='/infinite-imaginations/assets/infiniteimaginations/images/articles/1_x4Q0oWgZ-jqipEmliUGkTQ.gif' alt='Maverick putting on shades'></p><p>It will be an exciting year for 2019 as AI, AR and VR continue to gain traction and technology gets better and cheaper. I see the next year will be the integration of these technological trends into more smart devices and wearables. We could potentially see the rise (or the comeback) of smart glasses. Google Glass wasn‚Äôt ready for the consumer market years ago probably because of the price tag, battery life or privacy concerns, but changing the approach and purpose of the smart glass might change the perception of the device.</p>"},{"title":"VR and AR in the Mobile Web","url":"/infinite-imaginations/#/article/vr-and-ar-in-the-mobile-web","content":"<p>We have seen people peered into headsets to be immersed into a virtual world, seen people point their devices in all directions trying to look for something interesting around them. VR and AR apps are already available in app stores, and this can be a hindrance to get audiences on board. What if it was easily available in the mobile web?</p><h2>Virtual Reality</h2><p>VR is an interactive computer simulation taking the user into a virtual world. The computer generates a simulation and tricks the mind to believe whatever the user is seeing is real. It is usually associated with weird looking goggles, having long wires and mostly for entertainment. It was clunky, had low definition objects and just didn‚Äôt know what you need to do in the new virtual world. It was expensive to create, maintain and distribute to the consumer market.</p><p><img src='/infinite-imaginations/assets/infiniteimaginations/images/articles/0_-DooatHL85Zp8WQQ.png' alt='The Sensorama machine (scriptanime.wordpress.com)'></p><p>With VR catching up with technology at an exponential rate, goggles and headsets are getting smaller and lighter now where people can now wear it with ease. The quality has greatly improved also, projecting more realistic and smoother experiences. Price has also become more cheaper for the consumers. Companies have created their own VR equipment that consumers can buy without hurting their wallets.</p><h2>Augmented Reality</h2><p>AR is somewhat similar to VR. Instead of the computer generating the entire environment as a simulation, it creates virtual elements and embeds it in the real world. Just like VR, it required weird looking goggles, wires and were still connected to a computer. A common usage of AR for example is in heads up displays (HUD), where data or information is being displayed in transparent displays without making the users look away from the usual viewpoints.</p><p><img src='/infinite-imaginations/assets/infiniteimaginations/images/articles/0_lHEndTL-SXpjBvbX.png' alt='Virtual Fixtures‚Ää‚Äî‚Ääfirst A.R. system (1992, U.S. Air Force,WPAFB)'></p><p>AR once had a niche market but has now expanded into more broader industries such as gaming, education and businesses. AR is has become more popular with the success of Pokemen Go. As technology gets better and better, tech companies like Google and Apple has invested in incorporating AR in their devices for developers to explore the different possibilities.</p><h2>Technological Advancement</h2><p>Though it still requires a computer and other tracking devices, consumers are now able to purchase their own gear to jump into the virtual world. Developers too have been given the opportunity to create their own content and distribute it easily in the market. The most notable names that resonate in the market are Oculus and HTC Vive. Sony soon joined the bandwagon, creating their own VR peripherals which was cheaper than the PC versions.</p><p>With these technological advancements, it is not impossible to see that one day VR and AR would be fully supported on our smart devices. Tech giants have already started integrating the technology in smartphones. Companies already have taken the advantage of this by creating rich experiences for their users. While the developers at Mozilla and Google proposing the standardisation of WebXR API, web developers have started to create plugins to make VR and AR work for the web.</p><h2>VR and AR in the Web</h2><p>As all developers wait for the WebXR API to be standardised and released to the public, there are a lot of other alternatives where developers can utilise to showcare VR and AR for the web. The most popular one out there is Three.js by Ricardo Cabello (Mr.doob). But it can be daunting for developers who have little or no experience in the WebGL. An easier alternative would be A-Frame, a framework specifically designed to create rich VR experiences without having to know WebGL.</p><p data-height='265' data-theme-id='0' data-slug-hash='Mvmdzg' data-default-tab='html,result' data-user='oninross' data-pen-title='Hello World ‚Äî A-Frame' class='codepen'>See the Pen <a href='https://codepen.io/oninross/pen/Mvmdzg/'>Hello World ‚Äî A-Frame</a> by Nino Ross Rodriguez (<a href='https://codepen.io/oninross'>@oninross</a>) on <a href='https://codepen.io'>CodePen</a>.</p><script async src='https://static.codepen.io/assets/embed/ei.js'></script><p>A simple VR world like the example above was created only using 17 lines of HTML code. It works well on both desktop and mobile devices and users can dive in immediately without downloading or installing any additional software or hardware. There is an additional icon that is present on the screen where users can choose to be in full screen on desktop and stereoscopic VR on mobile devices. It gets more interesting on mobile devices because the device acts like the camera in the VR world which means wherever the user looks, it‚Äôs the actual representation in VR.</p><p><img src='/infinite-imaginations/assets/infiniteimaginations/images/articles/1_R6c3P43LzQgB6d3khSNnRQ.jpeg' alt='AR.js demo displaying AR objects using Hiro markers on mobile phones)'></p><p>AR.js was created by Jerome Etienne, focusing on making AR for the web a reality. Though it still relies and requires for markers to display elements on the screen, it‚Äôs still a relatively big step on bringing AR to the web. The sample above was created only using 30 lines of HTML code (a little bit larger to show 2 markers displaying 2 different objects). Just like it‚Äôs A-Frame sister, it works well on both desktop and mobile devices.</p><h2>The Future of VR and AR</h2><p>Google showcased WebARonARCore at their IO event this year. I managed to play around with the experimental technology in Chrome Canary and I must say that it looks really promising and it‚Äôs paving a brighter future for VR and AR in the web. Markerless AR on the web would make it more easier for users to get onboard and immersive without the need of downloading an app. The floodgates will surely be wide open when once this feature has been enabled by default and is standardised.</p><div class='video-container'><iframe src='https://www.youtube.com/embed/Zu6MXyfi-Ts' frameborder='0' allow='accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture' allowfullscreen></iframe></div><p>Imagine a collaborative virtual world where you only need a smartphone and you don‚Äôt need to download an app, where you don‚Äôt need to buy expensive equipment to experience VR, where you can visualise the information you need anywhere, anytime. It is truly an exciting time for the mobile web.</p>"},{"title":"Are QR Codes Making A Comeback?","url":"/infinite-imaginations/#/article/are-qr-codes-making-a-comeback","content":"<p>At some point in time, we have seen QR codes plastered all over the place, products, boxes and or posters. It was meant to serve as a bridge from the physical world to the internet, taking users to a webpage, a YouTube video or even make your smart device perform a specific task. The user experience imagined was to help users get to the information quickly. However, it was not the case. Though QR codes are thought to be extinct, these squared dots refuse to die and are rising once again in different forms and use cases.</p><h2>What ever happened to them?</h2><p>QR code system was invented to track vehicles during manufacturing and allowing high-speed component scanning. Taking that simple idea and applying it to the web industry, it was supposed to provide users with quick and specific information. If the QR code was on a poster about a concert, the user can simple scan the QR code and take the users to a webpage containing more information about the concert. That is just one of the possible applications.</p><p>Though the abbreviation means ‚ÄúQuick Response,‚Äù there were pitfalls in the user experience of the technology. At the time of the QR code boom, responsive web design was not yet common and viewing a website on your smartphone was literally viewing the desktop version in a tiny screen. It was a terrible experience. It might be one of the main reasons why users have chosen to abandon and even ignore QR codes when they are in sight.</p><p><img src='/infinite-imaginations/assets/infiniteimaginations/images/articles/1__a2jWgFENdelmblqXP8GFA.png' alt='R.I.P. QR Code'></p><p>We barely see QR codes anymore. Even if we did, we wouldn‚Äôt be bothered to pick up our smartphones to scan the codes. However, it has risen from the ashes and is being used differently and others have evolved to something else.</p><h2>‚ÄúI shall return‚Ä¶‚Äù‚Ää‚Äî‚ÄäQR Code</h2><p>Typing on a small touch screen has always been a problem for most users. Tech companies has always continued to improve keyboard typing on mobile devices ranging from auto-complete to swipe-typing. That partially solves typing for sentences that we normally to in our day to day lives. There are cases that a user will still need to type something out of the ordinary like a very long URL mixed with numbers and characters (need I mention both in small and big letters).</p><p>Cue in the QR Code.</p><h3>WeChat</h3><p><img src='/infinite-imaginations/assets/infiniteimaginations/images/articles/1_Mtg6pfjLWPMW52wLEYguhg.png' alt='WeChat Pay'></p><p>It is probably one of the mobile apps that has successfully utilised the QR code and there is no sign of stopping. It‚Äôs the one-stop-app for the Chinese audience where users can use the app to pay bills, order goods and services, transfer money to other users, and pay in stores. Stores would have a QR code on their counters, where the user would then scan these codes. The user would then have to key in how much they will have to pay and that‚Äôs it. It has simplified the user journey for the customers and made the experience a seamless one.</p><h3>Twitter / LinkedIn</h3><p><img src='/infinite-imaginations/assets/infiniteimaginations/images/articles/1_wGIvC4ut7xbpL6-J-y255Q.png' alt='LinkedIn QR Code Scanning'></p><p>Sharing contacts with people on a mobile phone can be tricky most of the time. Especially if you heard the name differently or got a number wrong. Twitter and LinkedIn have made it possible to easily share contacts with each other. Both apps have their own QR code generator and reader, so users would be able to generate and scan these codes in 2 taps. This way the person wouldn‚Äôt need to jot down the details and fumble trying to open their smartphones anymore.</p><h3>Snapcodes / Spotify Codes</h3><p><img src='/infinite-imaginations/assets/infiniteimaginations/images/articles/1_6yKPg8_Sn3DlWjJGyx9tKg.png' alt='Spotify Codes'></p><p>One of the factors that confuses users about QR codes is that most of the time, users don‚Äôt know what to do with QR codes. The blunt irony was that the QR code reader app was never installed on your device when you needed to scan, or there are no QR codes in sight when you finally have installed it. Snapchat and Spotify have evolved QR code generating into a different level that would reflect more of their brand. With Snapcodes having their ‚Äúghostly‚Äù logo and Spotify codes with their soundwaves, users would immediately know what app they should be using to scan these codes.</p><h2>Hidden little gems</h2><p>With apps like Snapchat, WeChat and LinkedIn paving the way, I believe that QR codes are making a subtle come-back in the industry. The term quick response is now living up to it‚Äôs name, where both tech giants have finally included the feature in their respective devices. Apple made it seamless by just pointing the camera on the QR code and a preview link to tell the user what it has decoded. Google too included it in their software. Though it required a little bit more steps than that of Apple‚Äôs, it still gets the job done.</p><p><img src='/infinite-imaginations/assets/infiniteimaginations/images/articles/1_H4achBqs-wJIVSmE_1BwAw.png' alt='Apple and Google phones now have built-in QR code scanners'></p><p>These little gems have helped improve the user experience for everyone. When cameras from Apple or Android scan these QR codes, it gives a preview link that has been decoded. This way it gives a sense of security to the user that what they are about to enter is something safe. The best part of all, it‚Äôs not a third-party app anymore. It would be simply taking out your phone and scanning the QR code to get to the endpoint quickly.</p><p>The humble QR code has come a long way from being a disjointed user experience to quietly being reintroduced back into the industry. These black and white in one form or another will aim to help us get from the physical world to the internet. Look out for these things, it may be your window to a virtual world.</p>"},{"title":"Identifying Objects Using Your Browser With TensorFlowJS","url":"/infinite-imaginations/#/article/identifying-objects-using-your-browser-with-tensorflowjs","content":"<p>You might be familiar with the TV show <strong><em><a href='https://en.wikipedia.org/wiki/Silicon_Valley_%28TV_series%29' target='_blank'>Silicon Valley</a></em></strong> and the <strong><em><a href='https://www.youtube.com/watch?v=ACmydtFDTGs' target='_blank'>‚ÄúHot Dog‚Äù episode</a></em></strong> where the cast created an app to simply (and yet hilariously) determine the object as a hot dog or not a hot dog. And it‚Äôs not science fiction anymore with applications, like Google Lens, rolled out to most modern smartphones. These days anyone can simply point their camera and get the information they need, quickly.</p><p><img src='/infinite-imaginations/assets/infiniteimaginations/images/articles/0_bIn7WeM9QxPCXKwq.gif' alt='Silicon Valley - Hotdog Episode'></p><p>There are services like <strong><em><a href='https://cloud.google.com/vision/' target='_blank'>Google Cloud Vision API</a></em></strong>, <strong><em><a href='https://aws.amazon.com/rekognition/' target='_blank'>AWS Rekognition</a></em></strong> and <strong><em><a href='https://clarifai.com/' target='_blank'>Clarifai</a></em></strong>‚Ää‚Äî‚Ääto name a few‚Ää‚Äî‚Ääthat are available in the market for anyone to implement and use. Though these services let you do to more with less code, it does come with a pay-as-you-go price tag. Also, it‚Äôs a generic image identifier and may have a different use case.</p><p>Enter: <strong><em>TensorFlowJS</em></strong>.</p><p><img src='/infinite-imaginations/assets/infiniteimaginations/images/articles/0_j6p7mjOZtptGhyNP.jpg' alt='TensorFlor.JS'></p><p>It‚Äôs a JavaScript library released by the Google Brain Team that brings machine learning for everyone. It was originally written in Python, C++ and CUDA. Thanks to the team, they have ported it to JavaScript, where it is commonly used in the browser. Though TensorFlowJS is not exactly the same as his big brother Python version, the library is already equipped with the necessary APIs to build and train models from scratch, run TensorFlow models and retrain pre-existing models, all the convenience of your browser.</p><p>TensorFlow has been circulating around my reading feeds and with Google‚Äôs recent IO event, it inspired and pushed me to get my hands dirty in machine learning.</p><h2>Road To Discovery</h2><p><img src='/infinite-imaginations/assets/infiniteimaginations/images/articles/0_OfYHB8isOCNP4D5l.jpg' alt='TensorFlor.JS'></p><p>Warnings from different sources suggest that, TensorFlow wouldn‚Äôt be helpful if you didn‚Äôt have any machine learning background. Python keeps popping up as the language of choice for developing in machine learning and it seemed that I needed to learn the basics in order to create to proceed. This was one of many hurdles that I encountered. But I was still determined to create my own image identifier.</p><h2>Warning: If you don‚Äôt have any Machine Learning background, TensorFlow is not for you</h2><p>The first step is always going back to basics and read the documentations at <strong><em><a href='https://js.tensorflow.org/' target='_blank'>TensorFlowJS‚Äôs website</a></em></strong>. It seemed to be pretty straightforward at first, but I was wrong. More questions surfaced and I was beginning to believe the warning signs earlier. Maybe I do need to learn about machine learning before I dive into TensorFlowJS. Even scouring YouTube for tutorials and references didn‚Äôt help much. I did manage to ‚Äúcreate‚Äù an image classifier locally in my machine but it was running in Python. I needed it to be client-side just like the <strong><em><a href='https://emojiscavengerhunt.withgoogle.com/' target='_blank'>Emoji Scavenger Hunt</a></em></strong>.</p><p>Having found the <strong><em><a href='https://github.com/google/emoji-scavenger-hunt' target='_blank'>repository</a></em></strong> to the Emoji Scavenger Hunt and hours of reverse engineering the codes to suit to my needs, I was able to finally create my own image classifier that works smoothly in the client-side.</p><h2>Teach it as if it was like a 2-year-old</h2><p>I thought that my biggest hurdle would be developing in Python. I was developing in a Windows environment initially and it was confusing and a pain to set up. But the moment I switched to a Mac environment, everything was smooth sailing. The biggest lesson that I learned was providing the system with good data. My colleagues told me in order to have results with high accuracy, you must provide good initial data.</p><p><img src='/infinite-imaginations/assets/infiniteimaginations/images/articles/0_CwMvCN1HXvikarnH.jpg' alt='&amp;quot;Teach it as if it were like a 2-year-old&amp;quot;'></p><p>An analogy to simply understand how machine learning works is, teaching it by showing images as if it was like a 2-year-old, where data is the set of images and the 2-year-old is the machine learning system. For example, if you want the child to learn what an apple is, you would show the child different pictures of apples only. Nothing else should be in the picture. No other fruits, no other elements. After a certain number of pictures that the child has seen, they will be able to know when they see an apple in real-life. On the other hand, if you give the child pictures with apples and oranges, apples and bananas, apples and grapes. The child will get confused when they see those fruits together.</p><p>The moral of the analogy is that the images that will be initially fed to the system for machine learning should be easy to comprehend for someone or something who doesn‚Äôt know what the subject is.</p><h2>Riddle Me This PWA</h2><blockquote>\"Riddle me this riddle me that<br>Random riddles taken out from the hat<br>When you know the answer take a snap<br>If you are correct I will give you a clap\"</blockquote><p>The goal was to come up with my own image identifier and put it into some good use. The Riddle Me This is a PWA that will show you random riddles of common items that can be found around your home. Your challenge is to find the answer and take a picture of it. If you are correct, you proceed with the other riddles. If you are wrong, well‚Ä¶keep guessing.</p><p>Have a go at the link below! Happy hunting!</p><p><img src='/infinite-imaginations/assets/infiniteimaginations/images/articles/1_qMV6N7nIkZ2vMcQPv8UmzQ.png' alt='Riddle Me This PWA'></p><p><a class='cta' href='https://riddles.infiniteimaginations.co/' target='_blank'>Riddle Me This PWA</a></p>"},{"title":"The Art of Minimalism with UX","url":"/infinite-imaginations/#/article/the-art-of-minimalism-with-ux","content":"<p>Minimalism is on the rise‚Ää‚Äî‚Ääbut what is it? Is it the style of art that can be found in architecture, paintings, sculptures and design that eliminates all non-essential forms or features? Or is it a form of lifestyle where you declutter your life from all unnecessary things.</p><p>Regardless of what minimalism is, it shares one common denominator‚Ää‚Äî‚Ää‚Äúeliminating the not needed and removing all distractions.‚Äù I have found out how minimalism has helped improve user experience.</p><h2>Journey to Minimalism</h2><p>I was hooked with minimalism before I fully understood the core concepts of it. My <strong><em><a href='https://www.infiniteimaginations.co/#/hello/'>online portfolio</a></em></strong> was due for a redesign and I wanted it to have a simple look and feel with a timeless design. I have tried to apply it and the result was being featured in Web Designer Depot as one of <strong><em><a href='https://www.webdesignerdepot.com/2017/01/the-best-new-portfolio-sites-january-2017/' target='_blank'>The Best New Portfolio Sites, January 2017</a></em></strong>. It received the following comment:</p><p><em>‚ÄúInfinite imaginations combines a bit of a ‚Äútechy‚Äù style with <strong>minimalism</strong>, understated animation, and the periodic table. I‚Äôm not even kidding about that. While the design does have its (miniscule) flaws, its <strong>reserved sense of style is both appealing and kind of relaxing</strong>.‚Äù‚Ää‚Äî‚ÄäEzequiel Bruni (Web Designer Depot)</em></p><p>I experimented with minimalism once more in one of my personal projects. The project was supposed to be for a beacons experiment that resulted into something different. It‚Äôs a progressive web app (PWA) that tells the users what time will the next bus will be arriving. I left the project running for some time and received the following as one of the comments:</p><p><em>‚ÄúGreat app. Really really like it, especially after going onto the nxtbus website every time I had to check if I hadn‚Äôt missed my bus already and also as a regular bus user. Also very <strong>aesthetically pleasing</strong>. Good job guys üëç‚Äù</em></p><p>Finally, I watched a documentary in Netflix titled ‚ÄúMinimalism: A Documentary About the Important Things.‚Äù I didn‚Äôt read the entire title, all I read was Minimalism and I watched it with the premise that I will be learning minimalism in art and design. Five minutes through the video, I was in for a different ride. The documentary took their viewers by showing minimalists from different walks of life striving to live a meaningful life with less. I discovered that minimalism can be also applied in a person‚Äôs lifestyle.</p><p>It got me to think further. Maybe minimalism can be applied everywhere‚Ää‚Äî‚Ääin a person‚Äôs lifestyle, in design and in development. The basic principles share one common factor, simplicity helps people improve one‚Äôs well-being. If minimalism can help improve a person‚Äôs well-being, maybe it can also help improve user experience.</p><h2>User Experience Today</h2><p>People are already plagued with different distractions of different types everyday. Just think about our smart devices. We can receive hundreds of notifications from social media, media and apps telling us to greet our friend a happy birthday, this person you have been following has bought a new shirt or an app just telling you to get up off your seat and walk around. There is the internet with a high-speed connection where one can open up multiple tabs, scrolling endlessly through pages and pages of clickbaits. Whatever kind of distraction this is, it takes away the user‚Äôs focus the main task at hand.</p><h2>Restaurant Kiosks</h2><p>One of the worst user experiences I have had with interfaces is eating at restaurants with iPads as their ordering menu. Some restaurants think that by replacing a server with an iPad will be more efficient. In some cases, this might be true. But not always, such as the interface like the one below‚Ä¶</p><p><img src='/infinite-imaginations/assets/infiniteimaginations/images/articles/1_CR1MIbKjGOyh7mmiBqKCtg.jpeg' alt='iPad Menu'></p><p>This image is definitely being too kind to my experience. The image above is already decent (and I couldn‚Äôt find an image of an iPad with a cluttered interface). The one we saw had a lot of ‚Äúads‚Äù selling what the restaurant has and it was difficult to find the food that we wanted. Just because having an iPad in a restaurant doesn‚Äôt make it high-tech or in trend. Management needs to also consider how the users will be using it.</p><h2>Apps and Websites</h2><p>Countless times I have seen apps and websites that are just painful, to the point that I wish I could unsee all of them. Entire sites or apps that has too much clutter in the page, distracting the users from performing the main task.</p><p>There came a time when building apps was the solution to everything. Trying to fit every single functionality in a 4-inch display is a must, giving everything to the user. Like the example below. It has too many features bombarding the user overwhelming them on what or how to use the app.</p><p><img src='/infinite-imaginations/assets/infiniteimaginations/images/articles/1_HvZcfP3vEIDbRurSiQkbTw.png' alt='app interface with a lot of buttons'></p><p>Another example as one of the most infamous websites is every designers‚Äô nightmare, <strong><em><a href='https://www.lingscars.com/' target='_blank'>Ling‚Äôs Cars</a></em></strong>. It just breaks almost every rule in design, specially with trying to give focus to the users‚Äô needs. It is not the prettiest site (pun intended). It just confuses all the users of what this site is actually doing.</p><p><img src='/infinite-imaginations/assets/infiniteimaginations/images/articles/1_Omtu_m4TjyguCeA2_CW4Bw.png' alt='Ling's Cars Website'></p><h2>Laws of UX</h2><p>There is a collection of principles that designers and developers can consider when designing and developing user interfaces called the Laws of UX. I have handed picked a few of them that correlates with minimalism.</p><p><img src='/infinite-imaginations/assets/infiniteimaginations/images/articles/1_hweZ1qB-Clsh1D2DCSSbsQ.gif' alt='Law's of UX'></p><p>Fitts‚Äôs Law<br><em>‚ÄúThe time to acquire a target is a function of the distance to and size of the target.‚Äù</em></p><p><img src='/infinite-imaginations/assets/infiniteimaginations/images/articles/1_hweZ1qB-Clsh1D2DCSSbsQ.gif' alt='Fitt's Law'></p><p>Call to actions are the elements we want our users to click on, usually buttons with a contrasting colour that has short clear text of what will happen if they click on it. We just have to help our users find and select these elements easily by designing an interface that has a clean and easy to understand as one of the characteristics of minimalism is clarity.</p><p>Hick‚Äôs Law<br><em>‚ÄúThe time it takes to make a decision increases with the number and complexity of choices.‚Äù</em></p><p><img src='/infinite-imaginations/assets/infiniteimaginations/images/articles/1_5HP5ppFTAU0Au8xOuN465g.gif' alt='Hick's Law'></p><p>Complicated interfaces will just overwhelm the users, hindering or even make mistakes along the process. We just have to make it simple for our users. Determine what the end goal is and help the users attain that objective the easiest way possible. Another characteristic of minimalism is removing all the clutter or removing non-functional decorative elements. This way, the interface can immediately give focus to the users what is the next action. The rule of thumb here is ‚Äúif it doesn‚Äôt serve a purpose for the user to reach their end goal, get rid of it.‚Äù</p><p>Jakob‚Äôs Law<br><em>‚ÄúUsers spend most of their time on other sites. This means that users prefer your site to work the same way as all the other sites they already know.‚Äù</em></p><p><img src='/infinite-imaginations/assets/infiniteimaginations/images/articles/1_Uhi8bjvZ_wzPFKeQow0pSw.gif' alt='Jacob's Law'></p><p>Learning something new could be a fun or painful experience for any user. Minimalism focuses on the functionality of every element, ensuring that the element is understood effortlessly. By presenting the user with familiar elements or common design patterns that can be found in other websites or everyday interfaces, it simplifies the learning process for the users.</p><p>Miller‚Äôs Law<br><em>‚ÄúThe average person can only keep seven (plus or minus two) items in their working memory.‚Äù</em></p><p>Complexity can be an exhausting job for a person‚Äôs memory especially with today‚Äôs everyday distractions. Minimalism is often associated with simplicity. By simplifying the interface and or process, it helps the user have an easy and effective means of achieving their goals. Limit the actions or things the users have to commit to memory in order to finish a task.</p><p>KISS Principle<br><em>‚ÄúOverload, clutter, and confusion are not attributes of information, they are failures of design.‚Äù‚Ää‚Äî‚Ää<strong>Edward Tufte</strong></em></p><p>People will always be attracted by bright colours and flamboyant designs. ‚ÄúThe bigger the better‚Äù they always say. They are already flooded enough with their own distractions so let‚Äôs make it easier for them to accomplish their main task. We may not know it but subconsciously, we tend to look for the simple solution. Minimalism is a philosophy, a movement, a lifestyle. No matter what you want to call it or how you want to use it, minimalism promotes the removal of unnecessary elements, keeping everything simple without losing meaning and clarity. Always take a step back and remember, <em>‚ÄúKeep It Simple, Stupid‚Äù</em>.</p>"},{"title":"Service Workers on iOS","url":"/infinite-imaginations/#/article/service-workers-on-ios","content":"<p>For every release of a new device is a release of an OS update or upgrade. Apple fanboys and developers were excited to see if anything from Safari Technology Preview will land in the update. On March 27, Apple held an event with rumours floating around about the most anticipated iOS 11.3 packed with features. One of the biggest rumours is the arrival of service workers.</p><h2>What is so important about iOS 11.3?</h2><p>There is a lot of updates that have been brought to the users. Most of them are bringing better experiences to the user like the new AR experiences, Animoji and the battery fix that has been plaguing iPhone users with the 11.2 version. There is, however, one feature that has made frontend developers all hyped up that is not mentioned in Apple news and blogs‚Ää‚Äî‚Ääthe arrival of service workers.</p><p>On December 20, 2017, WebKit tweeted the release notes for the Safari Technology Preview and Service Workers were enabled by default.</p><blockquote class='twitter-tweet' data-lang='en'><p lang='en' dir='ltr'>Release notes for today‚Äôs Safari Technology Preview release 46 update are now available. <a href='https://t.co/BSX3O8owjc'>https://t.co/BSX3O8owjc</a> <a href='https://t.co/nbctOukCvz'>pic.twitter.com/nbctOukCvz</a></p>&mdash; WebKit (@webkit) <a href='https://twitter.com/webkit/status/943541983569727496?ref_src=twsrc%5Etfw'>December 20, 2017</a></blockquote><script async src='https://platform.twitter.com/widgets.js' charset='utf-8'></script><p>What did this mean? Progressive Web Apps (PWA) are coming to iOS devices! Service Workers are the heart of every PWA. To know more about PWAs, have a read of the <strong><em><a href='/infinite-imaginations/infinite-imaginations/#/article/an-app-but-not-progressive-web-apps'>previous article</a></em></strong> I wrote. For months, developers have patiently waited for the service workers to arrive officially in iOS devices. We all hoped for the release during the March event, but wasn‚Äôt even mentioned.</p><p>I gave up hope when Twitter-verse was still complaining about the battery issue and shouting out at Apple to drop the update already. A few days later, they did drop the update without any big news. I grabbed an updated iPhone to see what features are available and visited <strong><em><a href='whatwebcando.today'>whatwebcando.today</a></em></strong> to check the features and this is what I saw:</p><p>‚úîÔ∏è Offline Storage<br>‚úîÔ∏è Offline Mode<br>‚ùå Local Notifications<br>‚ùå Push Messages<br>‚ùå Home Screen Installation<br>These are the most important features that can give a seamless experience for both Android and iOS. These features are already enabled by default in Android to give that ‚Äúapp-like‚Äù experience. We are now just waiting for iOS to play catch-up.</p><p>The core pillars of a PWA are Reliable, Fast and Engaging. These pillars enhance the user experience on both mobile and desktop sites.</p><p>Being reliable means that when it is launched from the user‚Äôs home screen, it will load instantly regardless of the network state. There will be no ‚Äúdown time‚Äù and will never see the downasaur. The PWAs will install on the user‚Äôs home screen (Home Screen Installation) and cache (Offline Storage/Mode)‚Ää‚Äî‚Ääthe necessary assets to bring an optimal experience without searching through the seas of apps in the app store.</p><p>Engaging means that the PWAs feel like a natural app on the device and is installable on the user‚Äôs home screen (Home Screen Installation) without the need of an app store. On top of that, push notifications (Local Notifications and Push Messages) help users re-engage with the site. These push notifications were once exclusive to apps, now it has arrived to the mobile web.</p><h2>So, what can a PWA do and not do in iOS?</h2><p>There is only little that you can do for now with only Offline Caching available for iOS. I have managed to tinker around with some of the PWAs that I have developed on iOS. Here are my findings:</p><h3>‚úîÔ∏è Offline Caching</h3><p>Hurray! The first step of a PWA has landed on iOS. With this feature, the service worker will cache the necessary assets for offline usage or when the network is not reliable. This will launch the PWA (once installed) quicker than usual keeping the users engaged and not drop off. This is helpful for any static or brochure type apps where a network connection could be crappy. Once installed, the user can browse through the app without relying too much on the network.</p><h3>‚ùå Home Screen Installation</h3><p>This one is a deal-breaker for me. One of the features that I like about PWA is letting the users know that they can ‚Äúinstall‚Äù the PWA on their home screen with a tap of a button. This is not yet implemented on iOS devices and hopefully we will see this in the future. A work-around for this is to create ‚ÄúAdd to home screen banner‚Äù for iOS devices. It will give simple instructions on how to add the PWA to the home screen.</p><h3>‚úîÔ∏è/‚ùå Offline Mode</h3><p>Once the user has added the PWA to the home screen, the device spins up another instance of the PWA. This means that if the user has launched the PWA from the home screen when offline or in a crappy network, it will load the PWA again from scratch and cache it again. Not only is it troublesome‚Ää‚Äî‚Ääit‚Äôs not a good user experience for iOS users.</p><h3>‚ùå Local Notifications / Push Messages</h3><p>If this feature manages to land in iOS devices, it might be the death of native apps. This enables users to receive notifications on their mobile devices without the need of installing an app and let the users engage quickly.</p><h2>Apple needs to play catch-up</h2><blockquote class='twitter-tweet' data-lang='en'><p lang='en' dir='ltr'>Not yet! It took Chrome a few milestones after basic SW support to fully land Web Push though. Perhaps they&#39;ll be explored in the future.</p>&mdash; Addy Osmani (@addyosmani) <a href='https://twitter.com/addyosmani/status/979725677766238208?ref_src=twsrc%5Etfw'>March 30, 2018</a></blockquote><script async src='https://platform.twitter.com/widgets.js' charset='utf-8'></script><p>Since the launch of the iPhone 3Gs, we have always held high expectations from Apple. With Apple lagging behind in web technologies, they must catch-up with the latest trends. We developers will have to be a little bit more patient in waiting for more service worker features. It will get there, we didn‚Äôt actually think that service workers would land in iOS because it might be the cause of death of their App Store.</p><p>It‚Äôs a start. The rest will eventually follow.</p>"},{"title":"Through The Looking Glass: An Overview of Visual Recognition","url":"/infinite-imaginations/#/article/through-the-looking-glass-an-overview-of-visual-recognition","content":"<p><img src='/infinite-imaginations/assets/infiniteimaginations/images/articles/1_H1dsEjTucJvnINFVSgELGw.jpeg' alt='&amp;quot;Face Finding from Mission: Impossible - Ghost Protocol&amp;quot;'></p><p>It‚Äôs like something straight out of a Sci-Fi movie ‚Äî machines, robots and androids being able to identify objects and faces with ease. But these days, early adaptations of visual recognition or image recognition technology have been made available today through services provided by the likes of Google and IBM.</p><p>Let‚Äôs take a journey of how computers and devices took the first steps looking into our world.</p><h2>Google Images</h2><p><img src='/infinite-imaginations/assets/infiniteimaginations/images/articles/1_TeKJrIGH2q6FMl3ANjdpxA.jpeg' alt='&amp;quot;Searching using images&amp;quot;'><br>Do you remember the days when Google was just a search engine and all you could search for was simple text? Google developers then expanded their search product and gave users results with images. The search engine indexed millions of images and the Image Search was born.</p><p>A few years later Google introduced the Search by Image feature, which allowed users to reverse image search directly into Google Search without any third-party add-ons.</p><h2>‚ÄúThere‚Äôs An App For That‚Ñ¢‚Äù</h2><p>Technologies were still young and limited back then. IBM Watson was still Deep Blue playing chess. The cloud was still a dodgy place to keep your files. You pretty much relied on Google to search for anything. Image recognition apps or programs were written either by companies with their own algorithm but were too expensive to produce, or piggybacked on Google‚Äôs Image Search which was the easier and cheaper solution.</p><p>Likely developed at the same time as Google Images, Google went on to release an app version of their image search feature. It was called Google Goggles and it allowed users to search by taking a picture. The app also featured the ability to recognise labels or landmarks without using a text-based search.</p><p>This meant people could search for virtually anything, immediately, by using their smartphones and not have the argues wait of getting back to a desktop.</p><p><img src='/infinite-imaginations/assets/infiniteimaginations/images/articles/1_9nf_R-nSEnjdlsSJlhc1dA.jpeg' alt='&amp;quot;Google Goggles&amp;quot;'></p><h2>Visual Recognition and Web Apps</h2><p>Let‚Äôs fast forward today‚Äôs date, where technology had a sudden growth spurt and gave us, users and developers, endless possibilities to play with.</p><p>We now have the ability to tinker with artificial intelligence, machine learning, deep learning, natural language processing and visual recognition to name just a few. Of course, we can always hire developers with specialties in artificial intelligence and machine learning, but it would cost us an arm and a leg. There are services from IBM Watson and Google Cloud Platform that provide developers ease of use, all with an affordable price tag.</p><h2>More Than Meets The Eye</h2><p>With the possibilities being endless, here are a few examples on how we can use these technologies at our disposal:</p><h2>‚ÄúEye See It‚Äù App</h2><p>There may be a time our visually challenged friends may need assistance in identifying an object or reading small text. With an app installed on their smartphones, it would be as easy as taking a picture and the app, replying to the user with voice, telling the users what it has seen. A user could take a picture of an unknown object to them and could reply, ‚ÄúI am most definitely looking at a sports car‚Äù.</p><h2>‚ÄúPlant-Eye-tion‚Äù App</h2><p>A possible idea for the plant lovers out there who may not be as well versed as our gardener friends. Gardeners would be a walking encyclopedia of knowledge of plants, carrying information about the plants they take care of. What if we had an app that by taking a picture of the flower or plant, it would give you the name of the picture taken? Not only that, would it give you the full details of the flower/plant, it could help you keep the thing alive sharing how many times per day it needs to be waters and weather it prefers sun or shade‚Ä¶ it can turn the hobbyist into an expert sharing the information relevant to your surroundings.</p><h2>‚ÄúEye Keeper‚Äù</h2><p>Another possibility is curating relevant and safe content to your social media wall in real time. Think about it, you‚Äôre at an event and there is a big digital wall that aggregates the pictures taken by the people and its uploaded in social media or in the servers. Currently, you have two choices, you have dedicated team members monitoring and curating the content or you give up full control and allow every post with the relevant tagging to be posted to the wall. One costs a lot of time and money, the other is a huge risk.</p><p>The visual recognition service can act as a gatekeeper, analysing the images before it actually reaches the live screen, automatically preventing any inappropriate images being displayed in the big screen.</p><h2>I Can Show You The World‚Ä¶</h2><p>Artificial intelligence has taken its first few steps to further see into our world. In the near future, we might not need machine learning and deep learning anymore to ‚Äúsee‚Äù and ‚Äúlearn.‚Äù Google Lens already took the first step in maximising the potential of the combination of visual recognition, deep learning and augmented reality.</p><p>I too, took a step in trying to see what this technology can do. Have a play at our little demo below. I highly suggest that you use your mobile phone for scanning images. Bear in mind though, that this is only a proof of concept. You might still get weird replies from the web app. Happy clicking!</p><p><img src='/infinite-imaginations/assets/infiniteimaginations/images/articles/1_1rHrf9YB4Ra_UzuPQ9Vq5w.png' alt='&amp;quot;Identify objects using camera&amp;quot;'></p><a class='cta' href='https://natseye.herokuapp.com/' target='_blank'>Nat's Eye</a>"},{"title":"An app but not‚Ää‚Äî‚ÄäProgressive Web Apps","url":"/infinite-imaginations/#/article/an-app-but-not-progressive-web-apps","content":"<h2>What‚Äôs In A Name?</h2><p>You might have read it somewhere or heard it from someone the buzz word Progressive Web App or PWA. W is for web in PWA so it might be web based. A is for app so does it mean it only runs on mobile phones? If it‚Äôs a web app, it runs best on desktop? What if there is no internet connection? I would define ‚Äúa Progressive Web App looks like an app, behaves like an app, but it‚Äôs still a website in its core.‚Äù</p><h2>So, What‚Äôs The Big Deal?</h2><p>We now know that PWAs are just websites, now what? What is so special about PWAs that we should be considering this new tech?</p><p>The magic behind all this wizardry is a script that runs in the background of the browser called a service worker, script lets the browser to have features like offline caching, background syncing and push notifications. These features were once exclusive to mobile apps but are now available to mobile and desktop browsers. The best part of PWAs are is that you don‚Äôt need an app store to share it with the world. Think of it as a website with superpowers.</p><h2>Mobile Web Is The Future</h2><p>A study conducted by Stone Temple Consulting finds that more than 55% of all traffic is coming from a mobile device and will continue to grow. By keeping in mind this statistic, we can see a clear pathway to where mobile web is going.</p><h2>The Lines Between Apps and Web Are Blurring</h2><p>Native web APIs are steadily growing for developers to use. With more and more features from mobile apps are slowly coming to the mobile web, the user experience between the two different platforms are getting more the same. Probably push notifications and background sync is one of the best features that came to the mobile browser.</p><h2>Service Workers Is Coming to iOS</h2><p>Apple devices are still the biggest hurdle when it comes to having a unified user experience for the mobile web. There is a lot of native web features that are available in Android devices but not supported in iOS. Service workers is one of them. Until around August 2017, Apple has updated their feature status page for service workers to In Development, which simply means that iOS devices might have the features that PWAs are known for. Only time will tell what features will be supported by their devices.</p><h2>Mobile Apps Are On A Decline</h2><p>Unless the apps that you have are in the likes of Facebook, FB Messenger or YouTube, your chances of getting and retaining new users are quite low. With the app boom over and on its decline, users today keep apps that they use often and frequently. Most of the time downloaded apps get lost in the sea of other apps and folders in their smartphones ending up forgotten.</p><h2>App Funnel Journey</h2><p>In a typical mobile app journey from looking for an app to doing what the app is meant to do, every step towards the end goal costs 20% of users. The number may vary depending on the app or the audience but generally users may drop at every step. It could be just because it wasn‚Äôt compatible with their device or they needed to login or create an account in order to use the app.</p><p><img src='/infinite-imaginations/assets/infiniteimaginations/images/articles/0_7EQFzDyNoiCNA_SH.jpg' alt='App Funnel Journey'></p><h2>Should I Be Building It In PWA?</h2><p>It always boils down to the requirements of the project. Below is a simple flowchart that I created to help decide on how your next project should be built.</p><p><img src='/infinite-imaginations/assets/infiniteimaginations/images/articles/0_e6mG4Ujm5MWvo42q.jpg' alt='App building flowchart'></p><h2>Let‚Äôs Get It On!</h2><p>PWAs may be the solution for your next or existing project or not. Specially with iOS finally getting on board with the PWA bandwagon, the possibilities could be endless. Creating PWAs for existing and new projects not only improve the user experience, it also improves performance.</p>"},{"title":"What I Have Learned From Building A Chatbot","url":"/infinite-imaginations/#/article/what-i-have-learned-from-building-a-chatbot","content":"<h2>What‚Äôs with the hype?</h2> <p>Technology nerds and enthusiasts have always dreamed of having a conversation with an artificial intelligence (AI). The living embodiment of the perfect AI would be JARVIS from the Iron Man movies. No keyboards, no mouse, no stylus. Just your voice, to have a conversation with your virtual personal assistant to do work for you.</p><p><img src='/infinite-imaginations/assets/infiniteimaginations/images/articles/1_krANTKbR7hP5h4YOUeiKbA.png' alt='Artificial Intellience'></p><p>But that is science fiction. AI is still in its infancy and it has a long way to go to reach maturity to beat the Turing test.</p><p>When Siri came out in the iPhone, it was the first digital personal assistant made for users. I was amazed how it instantly recognizes your requests using voice and comes back with a reply. A few years later, Google Assistant came out not only on smart devices, but in smart speakers as well. It was the first virtual personal assistant that has a two-way conversation. Then there was a sudden boom of chatbots.</p><h2>What is a chatbot?</h2> <p>A chatbot or a conversational UI is any interface that imitates chatting with a real human. It can be as simple as a chat window in a website or as complex interacting with an AI in a smart device. Whatever the medium may be if there is a two-way conversation, you are interacting with a chatbot.</p><p>There are a few types of conversational UIs in the industry, <strong><em>flow type, AI type,</em></strong> and <strong><em>hybrid type</em></strong>.</p><p><strong><em>Flow type</em></strong> is a tree-based kind of interaction, where the user is presented with choices and driven through a specific path. This path is pre-defined by the developer and can only ‚Äúgo‚Äù where the interface tells the user to go. An example here would be like the Choose Your Own Adventure books.</p><p><strong><em>AI type</em></strong> relies on artificial intelligence where the user can freely engage and have a real conversation. Something like Google Assistant, Siri and Cortana, there is an AI driving behind all the conversation.</p><p><strong><em>Hybrid type</em></strong> is the most common type of conversational UI and this is where chatbots come in. It‚Äôs a combination of flow type and AI where the users are driven through a specific path while they can engage with the chatbot in a conversation.</p><h2>Do you want to build a chatbot?</h2> <p>As a developer, you would only think that it would be as easy as getting code from the internet and deploy to a server. There was more to it than lines of code and pixels of art.</p><h3>Lesson 1: ‚ÄúDon‚Äôt build one because of the hype‚Äù</h3> <p><img src='/infinite-imaginations/assets/infiniteimaginations/images/articles/1_2jOLLbxpfYUuLcFG63H4Hg.png' alt='Hyper! Hyper'></p><p>It was my first mistake and I believe that it‚Äôs the golden rule in creating chatbots. Just because its trending now means that one should get into the band wagon and hoping for it to do its job. What I did was basically got Nathan Mk I off the shelf and got my friends to test it. Because it didn‚Äôt have a sole purpose, the users who tested it assumed that they were ‚Äútalking‚Äù to JARVIS.</p><p>In short, the chatbot should have a purpose. Introduce the chatbot to your audience. Tell them what is his purpose and what can he do. This way you are setting your audiences‚Äô expectations to the level of your chatbot‚Äôs capabilities.</p><h3>Lesson 2: Map the user journey</h3> <p>After concluding that the chatbot‚Äôs purpose should be my digital portfolio tour guide, I thought to myself: <em>‚Äúhow hard can it be? I have an online portfolio, there is my user journey.‚Äù</em> I ‚Äúprogrammed‚Äù <em>Nathan Mk II</em> to capture certain keywords and reply to them accordingly. However, I faced the problem of the possibility of users going to a different section of the site if they wanted to. Connecting them all together was troublesome. I got lost in my mind of how many different permutations can a user go from point A to wherever they wanted to. On top of that, there were a lot of holes that I didn‚Äôt foresee. It felt like it never ended.</p><p>Lesson learned, mapping the user journey will make a developer‚Äôs life easier when it‚Äôs time to program the chatbot. You will also foresee any holes that needed plugging.</p><h3>Lesson 3: Build the script</h3> <p>Since I didn‚Äôt map out the user journey properly, I thought I could write the script on the fly. Again, <em>‚Äúhow hard can it be? I have my website, there‚Äôs my script.‚Äù</em> Copy and paste should do it. As I progressed building my chatbot, I found it hard to come up with good replies and answers. It was either to broad, boring or had open-ended questions. This strayed the users from telling the chatbot the right keyword. ‚Äò</p><p>You need to lead your users. Guide them on what actions can be used to progress further. If you can‚Äôt come up with a meaning script, hire a copy writer. Solving logic is one thing and having a meaning conversation is another.</p><h3>Lesson 4: Add some flavor to it</h3> <p>Chatbots are still an inanimate object and text conversation can get boring quickly. However, it will say to whatever you program it to say. You can always mix it up with animated GIFs, photos, emojis, etc. (if applicable) just to keep the conversation interesting and fun. Give it a little personality as well. Giving the chatbot a little personality will make the users remember it.</p><h3>Lesson 5: ‚ÄúI need a human‚Äù</h3> <p>After endless hours of using and testing, I got used to navigating around the site using Nathan. I deployed it and let my friends try it. In the end, users got stuck in an infinite loop of <em>‚ÄúI don‚Äôt know‚Äù</em> replies. That could mean bad experience for the user. Instead of trapping your users in limbo, make sure that if your user is stuck at <strong>most 3</strong> ‚ÄúI don‚Äôt know,‚Äù give the option to talk to a human. We need to make our users happy by reaching their objective.</p><p><img src='/infinite-imaginations/assets/infiniteimaginations/images/articles/1_fUR6WYMiGgLhCG1YNfbgag.png' alt='Automated Bot Reply'></p><h3>Nathan Mk III</h3> <p>It was a good learning experience in creating Nathan and I had a lot of fun exploring this emerging technology. I learned that planning is essential because this is the backbone of the entire chatbot project. Just like any project that you may encounter, we need plan for the project, foresee the issues that may arise, and ask the questions needed. If planning is done properly, it would be smooth sailing from there onwards.</p><p>Chatbots are popping everywhere and uses natural language to communicate with their users. We can further enhance the user experience by utilizing voice to communicate. Voice interactions and voice user interface will be the next big thing in the industry. Here is a demo of what came out of my learning experience. Have a play!</p><p><img src='/infinite-imaginations/assets/infiniteimaginations/images/articles/1_LRlorzVH1x_ATZ6ZyE-mvA.png' alt='QR Code for Demo'><a class='cta' href='https://nat-ai.herokuapp.com/' target='_blank'>Nat AI</a></p>"},{"title":"UX, Beacons and the Physical Web","url":"/infinite-imaginations/#/article/ux-beacons-and-the-physical-web","content":"<h2>Getting The Record Straight With (i)Beacons</h2><p>Every time I try to explain the world of beacons to someone, it always ends up with iBeacons. You would think that iBeacons and beacons are the same because of the root word beacon. However, that is not the case. With today‚Äôs technology growing exponentially, buzzwords tend to multiply like rabbits and keeping up with all the new terms can be difficult.</p><p>iBeacon is not a physical product that you can hold. It‚Äôs a platform that Apple has developed and trademarked, as one of the early adapters of Bluetooth Low Energy (BLE) technology and released it along with iOS7 and the iBeacon API. BLE &quot;beacons‚Äù on the other hand are the devices that are strategically placed around an area, such as a museum or a store. They may be hidden from plain sight but still deliver an optimum user experience. These devices broadcast a small ‚Äúadvertisement‚Äù packet, a few times per second, for the mobile device to pick up and execute a certain command or action.</p><h2>I Got 99 Problems and an App Ain‚Äôt One</h2><p>One of the flaws of the iBeacon platform is that it requires an app for both the beacon and the mobile device to fully work properly so the user has to download the app even if they only use it once. I personally had trouble downloading the app that I needed, and that was just trying it out for fun. This is just one of the hurdles that one must consider when developing apps and beacons.</p><h2>Enter: The Physical Web + Beacons</h2><p>Google has its own open source BLE beacon platform called the EddyStone URL. The beacon broadcasts plain URLs for local smartphones to pick up, which the user taps and is opened in their browser, they don‚Äôt need to download an app. Does it feel like it‚Äôs too simple and seems like there is no difference? There is a difference, when you look at the bigger picture.</p><blockquote>‚ÄúIt‚Äôs the experience!‚Äù</blockquote><p>The main difference and selling point of BLE beacons is about with distribution and connecting to the target audience. Following are the most common ways beacons can be used and the pros and cons.</p><h2>QR Codes</h2><p>Probably the most common and popular way of distributing URLs to the user without making them type. However, it requires an app for the smartphone to be able to read the code and not everyone has a QR code reader installed (at the time of writing). I found myself frustrated when trying to discover where the QR code will take me and I didn‚Äôt have the app installed. It happened also the other way around, I had the QR code reader installed and no codes to scan.</p><h2>NFC</h2><p>This was the predecessor of QR codes and was supposed to be the next big thing. Unfortunately, most of the smartphones have it disabled by default and others might have difficulties enabling them specially if they don‚Äôt use it that much or didn‚Äôt know that the feature actually existed. What‚Äôs worst, Apple devices doesn‚Äôt have NFC (yet!).</p><h2>URL Shorteners</h2><p>Generally, humans are too lazy or clumsy to type on mobile devices, what more if you force the users to either type a long URL or a URL that has a mixture of lowercase and uppercase letters and numbers. I find myself fumbling on the virtual keyboard trying to type https://goo.gl/HP6Rpo (for example).</p><h2>App Notification Bombardment</h2><p>It may be useful to be notified by a beacon from time to time or when you are interested. But it can be irritating if you receive notifications when you don‚Äôt actually need to be notified.</p><h2>‚ÄúEnter the Physical Web‚Äù</h2><p>When I first watched the keynote presentation on ‚Äúbeacons‚Äù at the in Google IO event and saw the live demo, I couldn‚Äôt believe that it was that simple and the variety of applications that it can be applied to. The UX practitioners at Google coined the phrase, ‚ÄúWalk up and use anything‚Äù to make the experience better between offline and online. It is as simple as having Google Chrome installed, location and Bluetooth enabled and of course an internet connection. A simple swipe down on the notification drawer will display the low-priority notification if a beacon is nearby. A low-priority notification is a type of notification that you will only see it when you need it. It is not like an ordinary App notification where you can get bombarded with pings and alerts.</p><p>Though the ‚ÄúPhysical Web‚Äù and BLE ‚Äúbeacons‚Äù are still in its infancy, there are a lot of basic applications that it can be used on, such as museums, shops, bus stops or just places where there is a requirement for on-demand information. Here are a few real-world examples where beacons and the physical web can be implemented.</p><h2>Bus Stops</h2><p>People get their bus schedule either through an app, send an SMS or at the schedule posted at the stop. Sometimes, they do not have the app installed, or they need to make a time- sensitive decision, or timetables are confusing and it‚Äôs not real-time. If there was a beacon installed, a tap on the notification will bring out the real-time listing of available bus schedules immediately.</p><h2>Museums / Historical Landmarks</h2><p>Museums and historical landmarks can take the users to a whole new world with physical web and virtual reality (VR) or augmented reality (AR). A marker on the landmark can tell the users how to get to the microsite immediately without downloading any app. They take a peek through time and history just by using their mobile phones. There is a lot of potential and areas that can be explored with beacons tied up with VR/AR.</p><h2>Events</h2><p>Getting the audience to participate on digital engagements at events is quite tricky. In the past, we‚Äôve projected an online game on the wall and gave out pieces of paper with the URL, this wasn‚Äôt ideal but it was the easiest way to get the audience to participate. If beacons were available at that time, it would serve as an easy entry point to engage users in the digital space.</p><h2>Thinking Ahead</h2><p>More and more people are using smartphones when they search the internet. We need to think of creative ways of connecting our users easily from their mobile devices to the digital space easily. Mobile websites and web apps are becoming more app-like with the advent of progressive web apps (stay tuned for the next article). AR and VR have arrived in the mobile browser as well. With most of the people now using their mobile phones to connect in the internet, it is time to strike while the iron is hot.</p>"}]}