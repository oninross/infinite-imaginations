{
    "caseStudies": [
        {
            "title": "Elements",
            "category": "coding",
            "tldr": "An offline Progressive Web Application (PWA) of the periodic table of elements displaying the different information of the element.",
            "role": "Front-end Developer / Interface Designer",
            "challenges": [
                "Mobile apps are restricted to their respective app stores.  Creating tools will be more useful to everyone if there were no barriers.  I needed to deliver the content to the users quick and easy."
            ],
            "solutions": [
                "Elements is a progressive web app with a responsive mobile site in its core. Users can visit the page in their mobile devices, tablets and or desktops to view the periodic table of elements.  Users in Chrome Android will be prompted with a notification if they want to “pin” the page in their home screens. The icon in turn looks like an app, opens up like an app, and behaves like an app. The best part is that even if there is no internet connection, users can still view use the app."
            ],
            "technology": [
                "HTML / HTML5",
                "CSS / CSS3",
                "JavaScript / jQuery / TweenMax"
            ],
            "images": {
                "large": {
                    "url": "/assets/infiniteimaginations/images/large-elements.png",
                    "padding": 61
                },
                "small": "/assets/infiniteimaginations/images/small-elements.jpg"
            },
            "url": {
                "live": "http://elements.infiniteimaginations.co",
                "local": "/#/case-study/elements"
            }
        },
        {
            "title": "Physical Web and Beacons",
            "category": "coding",
            "tldr": "Hassle free delivering of on demand information to the user by using the beacons and the Physical Web.",
            "role": "Front-end Developer / UX Consultant",
            "challenges": [
                "Information can be at times be troublesome to the users.  Most of it is through the use of apps.  Apps are restricted by their own manufacturers and most of the time the app the users need are not supported by their devices."
            ],
            "solutions": [
                "Through the use of beacons, information can be delivered to the users easily.  There wouldn’t be a need of searching through millions of apps in the app store and downloading anymore.  Beacons transmit Eddystone URLs regularly to nearby mobile devices where the user can just tap the notification bringing them to a page with the relevant information.  It could be a web app telling the users the bus schedule of a particular bus stop or it could be a simple wayfinder in a museum or shopping mall.  The limitations are endless."
            ],
            "technology": [
                "HTML / HTML5",
                "CSS / CSS3",
                "JavaScript / jQuery / TweenMax"
            ],
            "images": {
                "large": {
                    "url": "/assets/infiniteimaginations/images/large-physical-web.png",
                    "padding": 60
                },
                "small": "/assets/infiniteimaginations/images/small-physical-web.jpg"
            },
            "url": {
                "live": null,
                "local": "/#/case-study/physical-web"
            }
        },
        {
            "title": "Adelphi Digital",
            "category": "coding",
            "tldr": "Adelphi Digital needed a new responsive website to cater its new content.  We also needed to make a clear statement to the world, <strong><em>\"we are going to create a complete agency website in 4 days.\"</em></strong>",
            "role": "Front-end Developer",
            "challenges": [
                "Everything was being done in one stream simultaneously.  We had one approved template design, the other templates were either still being designed or being revised, and I was the only front-ender to convert everything to HTML."
            ],
            "solutions": [
                "I had to make sure that the core framework of the website was robust yet flexible to fit any kind of content based from the design, and easy enough for the team to take over and populate the content.  It was just pure hard-work, passion and motivation that pushed us all to finish the website."
            ],
            "technology": [
                "HTML / HTML5",
                "CSS / CSS3",
                "JavaScript / jQuery / TweenMax"
            ],
            "images": {
                "large": {
                    "url": "/assets/infiniteimaginations/images/large-adelphi-digital.png",
                    "padding": 61
                },
                "small": "/assets/infiniteimaginations/images/small-adelphi-digital.jpg"
            },
            "url": {
                "live": "http://adelphi.digital",
                "local": "/#/case-study/adelphi-digital"
            }
        },
        {
            "title": "infinite imaginations BETA",
            "category": "design",
            "tldr": "A revolutionary and cutting edge website in design and technology, where most developers barely knew about the existing resources in the internet and the possibilities that it can do.",
            "role": "Front-end Developer / Designer",
            "challenges": [
                "The main objective was to animate the website using plain HTML.  The site was previously done in Flash and I needed to convert it to HTML.  Oh yeah, I was a noob in coding HTML."
            ],
            "solutions": [
                "With a crash course in HTML, CSS and JavaScript, I managed to replicate what I have done in Flash by using TweenMax and CSS3.  GreenSock just came out with its JavaScript version of their Flash plugin and I had just to be the first one to implement it. The website was featured in Web Designers Magazine."
            ],
            "technology": [
                "HTML / HTML5",
                "CSS / CSS3",
                "JavaScript / jQuery / TweenMax"
            ],
            "images": {
                "large": {
                    "url": "/assets/infiniteimaginations/images/large-infinite-imaginations-beta.png",
                    "padding": 61
                },
                "small": "/assets/infiniteimaginations/images/small-infinite-imaginations-beta.jpg"
            },
            "url": {
                "live": "http://beta.infiniteimaginations.co",
                "local": "/#/case-study/infinite-imaginations-beta"
            }
        },
        {
            "title": "The Jewel Box",
            "category": "design",
            "tldr": "An interactive touch screen to showcase the different venues and history about Mt. Fabre in different languages.",
            "role": "Interface Designer / Flash Developer",
            "challenges": [
                "We were provided with a low-powered machine to drive the touch screen, and we needed to display a lot of information in the device.  We also had to make sure that the interface was user-friendly for users who didn’t know how to use a touch screen."
            ],
            "solutions": [
                "We managed to deliver large amounts of content in different languages using XML.  Flash was still alive and mainstream and Apple was our peg.  By following the principles of Apple, we managed to make the user interface easy to use for anyone."
            ],
            "technology": [
                "Flash ActionScript 3",
                "TweenMax for ActionScript",
                "XML"
            ],
            "images": {
                "large": {
                    "url": "/assets/infiniteimaginations/images/large-the-jewel-box.png",
                    "padding": 70
                },
                "small": "/assets/infiniteimaginations/images/small-the-jewel-box.jpg"
            },
            "url": {
                "live": null,
                "local": "/#/case-study/the-jewel-box"
            }
        },
        {
            "title": "Envirobot",
            "category": "design",
            "tldr": "An interactive touchscreen application built into the chassis of a remote controlled robot circulating around Singapore high schools for students to play around with and at the same time learn about the environment.",
            "role": "Interface Designer / Flash Developer",
            "challenges": [
                "The iPad was already out in the market and users will expect a smooth user experience.  Touch screens on a Windows machine was just a simple tap here and a tap there.  We needed to make the application interesting enough for students to engage with it."
            ],
            "solutions": [
                "We took Apple as our basis for all the interaction and design guidelines.  We made sure that the design will be appealing to the student and yet intuitive enough for them to know how to use it.  Most of the time, I just had fun animating and creating the application.  It was probably one of the most funnest projects that I have worked on because we had the freedom to pour our creative juices into the project."
            ],
            "technology": [
                "Flash ActionScript 3",
                "TweenMax for ActionScript"
            ],
            "images": {
                "large": {
                    "url": "/assets/infiniteimaginations/images/large-envirobot.png",
                    "padding": 70
                },
                "small": "/assets/infiniteimaginations/images/small-envirobot.jpg"
            },
            "url": {
                "live": null,
                "local": "/#/case-study/envirobot"
            }
        }
    ],
    "articles": [
        {
            "title": "2018: The Year of Artificial Intelligence",
            "content": ""
        },
        {
            "title": "VR and AR in the Mobile Web",
            "content": ""
        },
        {
            "title": "Are QR Codes Making A Comeback?",
            "content": ""
        },
        {
            "title": "Identifying Objects Using Your Browser With TensorFlowJS",
            "content": ""
        },
        {
            "title": "The Art of Minimalism with UX",
            "content": ""
        },
        {
            "title": "Service Workers on iOS",
            "content": "<p>For every release of a new device is a release of an OS update or upgrade. Apple fanboys and developers were excited to see if anything from Safari Technology Preview will land in the update. On March 27, Apple held an event with rumours floating around about the most anticipated iOS 11.3 packed with features. One of the biggest rumours is the arrival of service workers.</p><h2>What is so important about iOS 11.3?</h2><p>There is a lot of updates that have been brought to the users. Most of them are bringing better experiences to the user like the new AR experiences, Animoji and the battery fix that has been plaguing iPhone users with the 11.2 version. There is, however, one feature that has made frontend developers all hyped up that is not mentioned in Apple news and blogs — the arrival of service workers.</p><p>On December 20, 2017, WebKit tweeted the release notes for the Safari Technology Preview and Service Workers were enabled by default.</p><blockquote class='twitter-tweet' data-lang='en'><p lang='en' dir='ltr'>Release notes for today’s Safari Technology Preview release 46 update are now available. <a href='https://t.co/BSX3O8owjc'>https://t.co/BSX3O8owjc</a> <a href='https://t.co/nbctOukCvz'>pic.twitter.com/nbctOukCvz</a></p>&mdash; WebKit (@webkit) <a href='https://twitter.com/webkit/status/943541983569727496?ref_src=twsrc%5Etfw'>December 20, 2017</a></blockquote><script async src='https://platform.twitter.com/widgets.js' charset='utf-8'></script><p>What did this mean? Progressive Web Apps (PWA) are coming to iOS devices! Service Workers are the heart of every PWA. To know more about PWAs, have a read of the <strong><em><a href='/#/article/an-app-but-not-progressive-web-apps'>previous article</a></em></strong> I wrote. For months, developers have patiently waited for the service workers to arrive officially in iOS devices. We all hoped for the release during the March event, but wasn’t even mentioned.</p><p>I gave up hope when Twitter-verse was still complaining about the battery issue and shouting out at Apple to drop the update already. A few days later, they did drop the update without any big news. I grabbed an updated iPhone to see what features are available and visited <strong><em><a href='whatwebcando.today'>whatwebcando.today</a></em></strong> to check the features and this is what I saw:</p><p>✔️ Offline Storage<br>✔️ Offline Mode<br>❌ Local Notifications<br>❌ Push Messages<br>❌ Home Screen Installation<br>These are the most important features that can give a seamless experience for both Android and iOS. These features are already enabled by default in Android to give that “app-like” experience. We are now just waiting for iOS to play catch-up.</p><p>The core pillars of a PWA are Reliable, Fast and Engaging. These pillars enhance the user experience on both mobile and desktop sites.</p><p>Being reliable means that when it is launched from the user’s home screen, it will load instantly regardless of the network state. There will be no “down time” and will never see the downasaur. The PWAs will install on the user’s home screen (Home Screen Installation) and cache (Offline Storage/Mode) — the necessary assets to bring an optimal experience without searching through the seas of apps in the app store.</p><p>Engaging means that the PWAs feel like a natural app on the device and is installable on the user’s home screen (Home Screen Installation) without the need of an app store. On top of that, push notifications (Local Notifications and Push Messages) help users re-engage with the site. These push notifications were once exclusive to apps, now it has arrived to the mobile web.</p><h2>So, what can a PWA do and not do in iOS?</h2><p>There is only little that you can do for now with only Offline Caching available for iOS. I have managed to tinker around with some of the PWAs that I have developed on iOS. Here are my findings:</p><h3>✔️ Offline Caching</h3><p>Hurray! The first step of a PWA has landed on iOS. With this feature, the service worker will cache the necessary assets for offline usage or when the network is not reliable. This will launch the PWA (once installed) quicker than usual keeping the users engaged and not drop off. This is helpful for any static or brochure type apps where a network connection could be crappy. Once installed, the user can browse through the app without relying too much on the network.</p><h3>❌ Home Screen Installation</h3><p>This one is a deal-breaker for me. One of the features that I like about PWA is letting the users know that they can “install” the PWA on their home screen with a tap of a button. This is not yet implemented on iOS devices and hopefully we will see this in the future. A work-around for this is to create “Add to home screen banner” for iOS devices. It will give simple instructions on how to add the PWA to the home screen.</p><h3>✔️/❌ Offline Mode</h3><p>Once the user has added the PWA to the home screen, the device spins up another instance of the PWA. This means that if the user has launched the PWA from the home screen when offline or in a crappy network, it will load the PWA again from scratch and cache it again. Not only is it troublesome — it’s not a good user experience for iOS users.</p><h3>❌ Local Notifications / Push Messages</h3><p>If this feature manages to land in iOS devices, it might be the death of native apps. This enables users to receive notifications on their mobile devices without the need of installing an app and let the users engage quickly.</p><h2>Apple needs to play catch-up</h2><blockquote class='twitter-tweet' data-lang='en'><p lang='en' dir='ltr'>Not yet! It took Chrome a few milestones after basic SW support to fully land Web Push though. Perhaps they&#39;ll be explored in the future.</p>&mdash; Addy Osmani (@addyosmani) <a href='https://twitter.com/addyosmani/status/979725677766238208?ref_src=twsrc%5Etfw'>March 30, 2018</a></blockquote><script async src='https://platform.twitter.com/widgets.js' charset='utf-8'></script><p>Since the launch of the iPhone 3Gs, we have always held high expectations from Apple. With Apple lagging behind in web technologies, they must catch-up with the latest trends. We developers will have to be a little bit more patient in waiting for more service worker features. It will get there, we didn’t actually think that service workers would land in iOS because it might be the cause of death of their App Store.</p><p>It’s a start. The rest will eventually follow.</p>"
        },
        {
            "title": "Through The Looking Glass: An Overview of Visual Recognition",
            "content": "<p><img src='/assets/infiniteimaginations/images/articles/1_H1dsEjTucJvnINFVSgELGw.jpeg' alt='&amp;quot;Face Finding from Mission: Impossible - Ghost Protocol&amp;quot;'></p><p>It’s like something straight out of a Sci-Fi movie — machines, robots and androids being able to identify objects and faces with ease. But these days, early adaptations of visual recognition or image recognition technology have been made available today through services provided by the likes of Google and IBM.</p><p>Let’s take a journey of how computers and devices took the first steps looking into our world.</p><h2>Google Images</h2><p><img src='/assets/infiniteimaginations/images/articles/1_TeKJrIGH2q6FMl3ANjdpxA.jpeg' alt='&amp;quot;Searching using images&amp;quot;'><br>Do you remember the days when Google was just a search engine and all you could search for was simple text? Google developers then expanded their search product and gave users results with images. The search engine indexed millions of images and the Image Search was born.</p><p>A few years later Google introduced the Search by Image feature, which allowed users to reverse image search directly into Google Search without any third-party add-ons.</p><h2>“There’s An App For That™”</h2><p>Technologies were still young and limited back then. IBM Watson was still Deep Blue playing chess. The cloud was still a dodgy place to keep your files. You pretty much relied on Google to search for anything. Image recognition apps or programs were written either by companies with their own algorithm but were too expensive to produce, or piggybacked on Google’s Image Search which was the easier and cheaper solution.</p><p>Likely developed at the same time as Google Images, Google went on to release an app version of their image search feature. It was called Google Goggles and it allowed users to search by taking a picture. The app also featured the ability to recognise labels or landmarks without using a text-based search.</p><p>This meant people could search for virtually anything, immediately, by using their smartphones and not have the argues wait of getting back to a desktop.</p><p><img src='/assets/infiniteimaginations/images/articles/1_9nf_R-nSEnjdlsSJlhc1dA.jpeg' alt='&amp;quot;Google Goggles&amp;quot;'></p><h2>Visual Recognition and Web Apps</h2><p>Let’s fast forward today’s date, where technology had a sudden growth spurt and gave us, users and developers, endless possibilities to play with.</p><p>We now have the ability to tinker with artificial intelligence, machine learning, deep learning, natural language processing and visual recognition to name just a few. Of course, we can always hire developers with specialties in artificial intelligence and machine learning, but it would cost us an arm and a leg. There are services from IBM Watson and Google Cloud Platform that provide developers ease of use, all with an affordable price tag.</p><h2>More Than Meets The Eye</h2><p>With the possibilities being endless, here are a few examples on how we can use these technologies at our disposal:</p><h2>“Eye See It” App</h2><p>There may be a time our visually challenged friends may need assistance in identifying an object or reading small text. With an app installed on their smartphones, it would be as easy as taking a picture and the app, replying to the user with voice, telling the users what it has seen. A user could take a picture of an unknown object to them and could reply, “I am most definitely looking at a sports car”.</p><h2>“Plant-Eye-tion” App</h2><p>A possible idea for the plant lovers out there who may not be as well versed as our gardener friends. Gardeners would be a walking encyclopedia of knowledge of plants, carrying information about the plants they take care of. What if we had an app that by taking a picture of the flower or plant, it would give you the name of the picture taken? Not only that, would it give you the full details of the flower/plant, it could help you keep the thing alive sharing how many times per day it needs to be waters and weather it prefers sun or shade… it can turn the hobbyist into an expert sharing the information relevant to your surroundings.</p><h2>“Eye Keeper”</h2><p>Another possibility is curating relevant and safe content to your social media wall in real time. Think about it, you’re at an event and there is a big digital wall that aggregates the pictures taken by the people and its uploaded in social media or in the servers. Currently, you have two choices, you have dedicated team members monitoring and curating the content or you give up full control and allow every post with the relevant tagging to be posted to the wall. One costs a lot of time and money, the other is a huge risk.</p><p>The visual recognition service can act as a gatekeeper, analysing the images before it actually reaches the live screen, automatically preventing any inappropriate images being displayed in the big screen.</p><h2>I Can Show You The World…</h2><p>Artificial intelligence has taken its first few steps to further see into our world. In the near future, we might not need machine learning and deep learning anymore to “see” and “learn.” Google Lens already took the first step in maximising the potential of the combination of visual recognition, deep learning and augmented reality.</p><p>I too, took a step in trying to see what this technology can do. Have a play at our little demo below. I highly suggest that you use your mobile phone for scanning images. Bear in mind though, that this is only a proof of concept. You might still get weird replies from the web app. Happy clicking!</p><p><img src='/assets/infiniteimaginations/images/articles/1_1rHrf9YB4Ra_UzuPQ9Vq5w.png' alt='&amp;quot;Identify objects using camera&amp;quot;'></p><a class='cta' href='https://natseye.herokuapp.com/' target='_blank'>Nat's Eye</a>"
        },
        {
            "title": "An app but not — Progressive Web Apps",
            "content": "<h2>What’s In A Name?</h2><p>You might have read it somewhere or heard it from someone the buzz word Progressive Web App or PWA. W is for web in PWA so it might be web based. A is for app so does it mean it only runs on mobile phones? If it’s a web app, it runs best on desktop? What if there is no internet connection? I would define “a Progressive Web App looks like an app, behaves like an app, but it’s still a website in its core.”</p><h2>So, What’s The Big Deal?</h2><p>We now know that PWAs are just websites, now what? What is so special about PWAs that we should be considering this new tech?</p><p>The magic behind all this wizardry is a script that runs in the background of the browser called a service worker, script lets the browser to have features like offline caching, background syncing and push notifications. These features were once exclusive to mobile apps but are now available to mobile and desktop browsers. The best part of PWAs are is that you don’t need an app store to share it with the world. Think of it as a website with superpowers.</p><h2>Mobile Web Is The Future</h2><p>A study conducted by Stone Temple Consulting finds that more than 55% of all traffic is coming from a mobile device and will continue to grow. By keeping in mind this statistic, we can see a clear pathway to where mobile web is going.</p><h2>The Lines Between Apps and Web Are Blurring</h2><p>Native web APIs are steadily growing for developers to use. With more and more features from mobile apps are slowly coming to the mobile web, the user experience between the two different platforms are getting more the same. Probably push notifications and background sync is one of the best features that came to the mobile browser.</p><h2>Service Workers Is Coming to iOS</h2><p>Apple devices are still the biggest hurdle when it comes to having a unified user experience for the mobile web. There is a lot of native web features that are available in Android devices but not supported in iOS. Service workers is one of them. Until around August 2017, Apple has updated their feature status page for service workers to In Development, which simply means that iOS devices might have the features that PWAs are known for. Only time will tell what features will be supported by their devices.</p><h2>Mobile Apps Are On A Decline</h2><p>Unless the apps that you have are in the likes of Facebook, FB Messenger or YouTube, your chances of getting and retaining new users are quite low. With the app boom over and on its decline, users today keep apps that they use often and frequently. Most of the time downloaded apps get lost in the sea of other apps and folders in their smartphones ending up forgotten.</p><h2>App Funnel Journey</h2><p>In a typical mobile app journey from looking for an app to doing what the app is meant to do, every step towards the end goal costs 20% of users. The number may vary depending on the app or the audience but generally users may drop at every step. It could be just because it wasn’t compatible with their device or they needed to login or create an account in order to use the app.</p><p><img src='/assets/infiniteimaginations/images/articles/0_7EQFzDyNoiCNA_SH.jpg' alt='App Funnel Journey'></p><h2>Should I Be Building It In PWA?</h2><p>It always boils down to the requirements of the project. Below is a simple flowchart that I created to help decide on how your next project should be built.</p><p><img src='/assets/infiniteimaginations/images/articles/0_e6mG4Ujm5MWvo42q.jpg' alt='App building flowchart'></p><h2>Let’s Get It On!</h2><p>PWAs may be the solution for your next or existing project or not. Specially with iOS finally getting on board with the PWA bandwagon, the possibilities could be endless. Creating PWAs for existing and new projects not only improve the user experience, it also improves performance.</p>"
        },
        {
            "title": "What I Have Learned From Building A Chatbot",
            "content": "<h2>What’s with the hype?</h2> <p>Technology nerds and enthusiasts have always dreamed of having a conversation with an artificial intelligence (AI). The living embodiment of the perfect AI would be JARVIS from the Iron Man movies. No keyboards, no mouse, no stylus. Just your voice, to have a conversation with your virtual personal assistant to do work for you.</p><p><img src='/assets/infiniteimaginations/images/articles/1_krANTKbR7hP5h4YOUeiKbA.png' alt='Artificial Intellience'></p><p>But that is science fiction. AI is still in its infancy and it has a long way to go to reach maturity to beat the Turing test.</p><p>When Siri came out in the iPhone, it was the first digital personal assistant made for users. I was amazed how it instantly recognizes your requests using voice and comes back with a reply. A few years later, Google Assistant came out not only on smart devices, but in smart speakers as well. It was the first virtual personal assistant that has a two-way conversation. Then there was a sudden boom of chatbots.</p><h2>What is a chatbot?</h2> <p>A chatbot or a conversational UI is any interface that imitates chatting with a real human. It can be as simple as a chat window in a website or as complex interacting with an AI in a smart device. Whatever the medium may be if there is a two-way conversation, you are interacting with a chatbot.</p><p>There are a few types of conversational UIs in the industry, <strong><em>flow type, AI type,</em></strong> and <strong><em>hybrid type</em></strong>.</p><p><strong><em>Flow type</em></strong> is a tree-based kind of interaction, where the user is presented with choices and driven through a specific path. This path is pre-defined by the developer and can only “go” where the interface tells the user to go. An example here would be like the Choose Your Own Adventure books.</p><p><strong><em>AI type</em></strong> relies on artificial intelligence where the user can freely engage and have a real conversation. Something like Google Assistant, Siri and Cortana, there is an AI driving behind all the conversation.</p><p><strong><em>Hybrid type</em></strong> is the most common type of conversational UI and this is where chatbots come in. It’s a combination of flow type and AI where the users are driven through a specific path while they can engage with the chatbot in a conversation.</p><h2>Do you want to build a chatbot?</h2> <p>As a developer, you would only think that it would be as easy as getting code from the internet and deploy to a server. There was more to it than lines of code and pixels of art.</p><h3>Lesson 1: “Don’t build one because of the hype”</h3> <p><img src='/assets/infiniteimaginations/images/articles/1_2jOLLbxpfYUuLcFG63H4Hg.png' alt='Hyper! Hyper'></p><p>It was my first mistake and I believe that it’s the golden rule in creating chatbots. Just because its trending now means that one should get into the band wagon and hoping for it to do its job. What I did was basically got Nathan Mk I off the shelf and got my friends to test it. Because it didn’t have a sole purpose, the users who tested it assumed that they were “talking” to JARVIS.</p><p>In short, the chatbot should have a purpose. Introduce the chatbot to your audience. Tell them what is his purpose and what can he do. This way you are setting your audiences’ expectations to the level of your chatbot’s capabilities.</p><h3>Lesson 2: Map the user journey</h3> <p>After concluding that the chatbot’s purpose should be my digital portfolio tour guide, I thought to myself: <em>“how hard can it be? I have an online portfolio, there is my user journey.”</em> I “programmed” <em>Nathan Mk II</em> to capture certain keywords and reply to them accordingly. However, I faced the problem of the possibility of users going to a different section of the site if they wanted to. Connecting them all together was troublesome. I got lost in my mind of how many different permutations can a user go from point A to wherever they wanted to. On top of that, there were a lot of holes that I didn’t foresee. It felt like it never ended.</p><p>Lesson learned, mapping the user journey will make a developer’s life easier when it’s time to program the chatbot. You will also foresee any holes that needed plugging.</p><h3>Lesson 3: Build the script</h3> <p>Since I didn’t map out the user journey properly, I thought I could write the script on the fly. Again, <em>“how hard can it be? I have my website, there’s my script.”</em> Copy and paste should do it. As I progressed building my chatbot, I found it hard to come up with good replies and answers. It was either to broad, boring or had open-ended questions. This strayed the users from telling the chatbot the right keyword. ‘</p><p>You need to lead your users. Guide them on what actions can be used to progress further. If you can’t come up with a meaning script, hire a copy writer. Solving logic is one thing and having a meaning conversation is another.</p><h3>Lesson 4: Add some flavor to it</h3> <p>Chatbots are still an inanimate object and text conversation can get boring quickly. However, it will say to whatever you program it to say. You can always mix it up with animated GIFs, photos, emojis, etc. (if applicable) just to keep the conversation interesting and fun. Give it a little personality as well. Giving the chatbot a little personality will make the users remember it.</p><h3>Lesson 5: “I need a human”</h3> <p>After endless hours of using and testing, I got used to navigating around the site using Nathan. I deployed it and let my friends try it. In the end, users got stuck in an infinite loop of <em>“I don’t know”</em> replies. That could mean bad experience for the user. Instead of trapping your users in limbo, make sure that if your user is stuck at <strong>most 3</strong> “I don’t know,” give the option to talk to a human. We need to make our users happy by reaching their objective.</p><p><img src='/assets/infiniteimaginations/images/articles/1_fUR6WYMiGgLhCG1YNfbgag.png' alt='Automated Bot Reply'></p><h3>Nathan Mk III</h3> <p>It was a good learning experience in creating Nathan and I had a lot of fun exploring this emerging technology. I learned that planning is essential because this is the backbone of the entire chatbot project. Just like any project that you may encounter, we need plan for the project, foresee the issues that may arise, and ask the questions needed. If planning is done properly, it would be smooth sailing from there onwards.</p><p>Chatbots are popping everywhere and uses natural language to communicate with their users. We can further enhance the user experience by utilizing voice to communicate. Voice interactions and voice user interface will be the next big thing in the industry. Here is a demo of what came out of my learning experience. Have a play!</p><p><img src='/assets/infiniteimaginations/images/articles/1_LRlorzVH1x_ATZ6ZyE-mvA.png' alt='QR Code for Demo'><a class='cta' href='https://nat-ai.herokuapp.com/' target='_blank'>Nat AI</a></p>"
        },
        {
            "title": "UX, Beacons and the Physical Web",
            "content": "<h2>Getting The Record Straight With (i)Beacons</h2><p>Every time I try to explain the world of beacons to someone, it always ends up with iBeacons. You would think that iBeacons and beacons are the same because of the root word beacon. However, that is not the case. With today’s technology growing exponentially, buzzwords tend to multiply like rabbits and keeping up with all the new terms can be difficult.</p><p>iBeacon is not a physical product that you can hold. It’s a platform that Apple has developed and trademarked, as one of the early adapters of Bluetooth Low Energy (BLE) technology and released it along with iOS7 and the iBeacon API. BLE &quot;beacons” on the other hand are the devices that are strategically placed around an area, such as a museum or a store. They may be hidden from plain sight but still deliver an optimum user experience. These devices broadcast a small “advertisement” packet, a few times per second, for the mobile device to pick up and execute a certain command or action.</p><h2>I Got 99 Problems and an App Ain’t One</h2><p>One of the flaws of the iBeacon platform is that it requires an app for both the beacon and the mobile device to fully work properly so the user has to download the app even if they only use it once. I personally had trouble downloading the app that I needed, and that was just trying it out for fun. This is just one of the hurdles that one must consider when developing apps and beacons.</p><h2>Enter: The Physical Web + Beacons</h2><p>Google has its own open source BLE beacon platform called the EddyStone URL. The beacon broadcasts plain URLs for local smartphones to pick up, which the user taps and is opened in their browser, they don’t need to download an app. Does it feel like it’s too simple and seems like there is no difference? There is a difference, when you look at the bigger picture.</p><blockquote>“It’s the experience!”</blockquote><p>The main difference and selling point of BLE beacons is about with distribution and connecting to the target audience. Following are the most common ways beacons can be used and the pros and cons.</p><h2>QR Codes</h2><p>Probably the most common and popular way of distributing URLs to the user without making them type. However, it requires an app for the smartphone to be able to read the code and not everyone has a QR code reader installed (at the time of writing). I found myself frustrated when trying to discover where the QR code will take me and I didn’t have the app installed. It happened also the other way around, I had the QR code reader installed and no codes to scan.</p><h2>NFC</h2><p>This was the predecessor of QR codes and was supposed to be the next big thing. Unfortunately, most of the smartphones have it disabled by default and others might have difficulties enabling them specially if they don’t use it that much or didn’t know that the feature actually existed. What’s worst, Apple devices doesn’t have NFC (yet!).</p><h2>URL Shorteners</h2><p>Generally, humans are too lazy or clumsy to type on mobile devices, what more if you force the users to either type a long URL or a URL that has a mixture of lowercase and uppercase letters and numbers. I find myself fumbling on the virtual keyboard trying to type https://goo.gl/HP6Rpo (for example).</p><h2>App Notification Bombardment</h2><p>It may be useful to be notified by a beacon from time to time or when you are interested. But it can be irritating if you receive notifications when you don’t actually need to be notified.</p><h2>“Enter the Physical Web”</h2><p>When I first watched the keynote presentation on “beacons” at the in Google IO event and saw the live demo, I couldn’t believe that it was that simple and the variety of applications that it can be applied to. The UX practitioners at Google coined the phrase, “Walk up and use anything” to make the experience better between offline and online. It is as simple as having Google Chrome installed, location and Bluetooth enabled and of course an internet connection. A simple swipe down on the notification drawer will display the low-priority notification if a beacon is nearby. A low-priority notification is a type of notification that you will only see it when you need it. It is not like an ordinary App notification where you can get bombarded with pings and alerts.</p><p>Though the “Physical Web” and BLE “beacons” are still in its infancy, there are a lot of basic applications that it can be used on, such as museums, shops, bus stops or just places where there is a requirement for on-demand information. Here are a few real-world examples where beacons and the physical web can be implemented.</p><h2>Bus Stops</h2><p>People get their bus schedule either through an app, send an SMS or at the schedule posted at the stop. Sometimes, they do not have the app installed, or they need to make a time- sensitive decision, or timetables are confusing and it’s not real-time. If there was a beacon installed, a tap on the notification will bring out the real-time listing of available bus schedules immediately.</p><h2>Museums / Historical Landmarks</h2><p>Museums and historical landmarks can take the users to a whole new world with physical web and virtual reality (VR) or augmented reality (AR). A marker on the landmark can tell the users how to get to the microsite immediately without downloading any app. They take a peek through time and history just by using their mobile phones. There is a lot of potential and areas that can be explored with beacons tied up with VR/AR.</p><h2>Events</h2><p>Getting the audience to participate on digital engagements at events is quite tricky. In the past, we’ve projected an online game on the wall and gave out pieces of paper with the URL, this wasn’t ideal but it was the easiest way to get the audience to participate. If beacons were available at that time, it would serve as an easy entry point to engage users in the digital space.</p><h2>Thinking Ahead</h2><p>More and more people are using smartphones when they search the internet. We need to think of creative ways of connecting our users easily from their mobile devices to the digital space easily. Mobile websites and web apps are becoming more app-like with the advent of progressive web apps (stay tuned for the next article). AR and VR have arrived in the mobile browser as well. With most of the people now using their mobile phones to connect in the internet, it is time to strike while the iron is hot.</p>"
        }
    ]
}